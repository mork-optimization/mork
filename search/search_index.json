{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#mork-metaheuristic-optimization-framework","title":"MORK: Metaheuristic Optimization framewoRK","text":""},{"location":"#what","title":"What","text":"<p>Mork is a framework for developing approaches for NP-Hard problems using the JVM.  It is currently under heavy development.</p>"},{"location":"#why-use-it","title":"Why use it","text":"<p>The idea of the project is to provide both high quality and tested componentes that can be used as is, and a developing framework to create new metaheuristic approaches for different kind of problems. A non extensive list of its current main benefits are:</p> <ul> <li>Automatic experiment parallelization</li> <li>Automatic results report generation</li> <li>Guaranteed reproducibility, even in high concurrency environments, by using the provided RandomManager.</li> <li>Can execute anywhere (at least, anywhere where Java and Docker can!). Easily build Docker containers that can execute almost anywhere.</li> <li>Automatic benchmarking and optional timings adjustment.</li> <li>Nice web interface to visualize solution quality and experiment progress.</li> </ul> <ul> <li>And more!</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<p>TLDR: Automatically generate a project using https://generator.mork-optimization.com/,  import in your favourite IDE and start working!</p> <p>See Getting started page in the Official Documentation for more details.</p>"},{"location":"#citing","title":"Citing","text":"<p>If this project is useful for any research, please consider citing the original paper https://doi.org/10.1162/evco_a_00317</p>"},{"location":"#bibtext","title":"Bibtext","text":"<pre><code>@article{10.1162/evco_a_00317,\n    author = {Mart\u00edn-Santamar\u00eda, Ra\u00fal and Cavero, Sergio and Herr\u00e1n, Alberto and Duarte, Abraham and Colmenar, J. Manuel},\n    title = \"{A practical methodology for reproducible experimentation: an application to the Double-row Facility Layout Problem}\",\n    journal = {Evolutionary Computation},\n    pages = {1-35},\n    year = {2022},\n    month = {11},\n    abstract = \"{Reproducibility of experiments is a complex task in stochastic methods such as evolutionary algorithms or metaheuristics in general. Many works from the literature give general guidelines to favor reproducibility. However, none of them provide both a practical set of steps and also software tools to help on this process. In this paper, we propose a practical methodology to favor reproducibility in optimization problems tackled with stochastic methods. This methodology is divided into three main steps, where the researcher is assisted by software tools which implement state-of-theart techniques related to this process. The methodology has been applied to study the Double Row Facility Layout Problem, where we propose a new algorithm able to obtain better results than the state-of-the-art methods. To this aim, we have also replicated the previous methods in order to complete the study with a new set of larger instances. All the produced artifacts related to the methodology and the study of the target problem are available in Zenodo.}\",\n    issn = {1063-6560},\n    doi = {10.1162/evco_a_00317},\n    url = {https://doi.org/10.1162/evco\\_a\\_00317},\n    eprint = {https://direct.mit.edu/evco/article-pdf/doi/10.1162/evco\\_a\\_00317/2057545/evco\\_a\\_00317.pdf},\n}\n</code></pre>"},{"location":"#citing-artifacts","title":"Citing artifacts","text":"<p>Artifacts, docs, and source code are automatically archived in Zenodo with each release. See:   for more information.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Issues, suggestions or any contribution in general are welcome!  Before doing any mayor refactor / contribution, get in touch!</p> <p>The current development version is a Maven project structured in the following modules:</p> Module Description common Basic and fundamental Mork classes / building blocks: algorithms, solutions, instances, helper methods, etc. core Mork engine: this is where the magic happens. Parallelization, report generation, web interface, dependency injection, and much more! autoconfig Automatic configuration procedures that allow you to easily tune algorithms. template Base project used by the web generator to create the project zip files. example-tsp Example project implementation using Mork, the classic Travelling Salesman Problem. integration-tests Integration tests used by Mork developers to validate the whole framework interactions and behaviour. <p>Remember depending on your needs when developing approaches using Mork you may easily add/remove module dependencies in the <code>pom.xml</code> file.</p>"},{"location":"#powered-by-mork","title":"Powered by Mork","text":"<p>Below is a list of research articles leveraging Mork to tackle optimization problems:</p> <ul> <li>An Efficient Fixed Set Search for the Covering Location with Interconnected Facilities Problem (I. Lozano-Osorio, J. S\u00e1nchez-Oro, A. Mart\u00ednez-Gavara, AD. L\u00f3pez-S\u00e1nchez, and A. Duarte, 2023). Link to the published paper.</li> <li>Multi-Round Influence Maximization: A Variable Neighborhood Search Approach (I. Lozano-Osorio, J. S\u00e1nchez-Oro, and A. Duarte, 2023). Link to the published paper.</li> <li>Dynamic Path Relinking for the Target Set Selection problem (I. Lozano-Osorio, A. Oliva-Garc\u00eda, and J. S\u00e1nchez-Oro, 2023). Link to the published paper.</li> <li>An efficient and effective GRASP algorithm for the Budget Influence Maximization Problem (I. Lozano-Osorio, J. S\u00e1nchez-Oro, and A. Duarte 2023). Link to the published paper.   </li> <li>Strategic oscillation tabu search for improved hierarchical graph drawing (S. Cavero, E. G. Pardo, F. Glover, and R. Mart\u00ed, 2024). Link to the published paper.</li> <li>General Variable Neighborhood Search for the optimization of software quality (J. Yuste, E. G. Pardo, and A. Duarte, 2024). </li> <li>Multi-objective general variable neighborhood search for software maintainability optimization (J. Yuste, E. G. Pardo, A. Duarte, and J.K. Hao, 2024).</li> </ul>"},{"location":"apidocs/legal/jquery/","title":"Jquery","text":""},{"location":"apidocs/legal/jquery/#jquery-v371","title":"jQuery v3.7.1","text":""},{"location":"apidocs/legal/jquery/#jquery-license","title":"jQuery License","text":"<pre><code>jQuery v 3.7.1\nCopyright OpenJS Foundation and other contributors, https://openjsf.org/\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n</code></pre>"},{"location":"apidocs/legal/jqueryUI/","title":"jqueryUI","text":""},{"location":"apidocs/legal/jqueryUI/#jquery-ui-v1132","title":"jQuery UI v1.13.2","text":""},{"location":"apidocs/legal/jqueryUI/#jquery-ui-license","title":"jQuery UI License","text":"<pre><code>Copyright jQuery Foundation and other contributors, https://jquery.org/\n\nThis software consists of voluntary contributions made by many\nindividuals. For exact contribution history, see the revision history\navailable at https://github.com/jquery/jquery-ui\n\nThe following license applies to all parts of this software except as\ndocumented below:\n\n====\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n====\n\nCopyright and related rights for sample code are waived via CC0. Sample\ncode is defined as all source code contained within the demos directory.\n\nCC0: http://creativecommons.org/publicdomain/zero/1.0/\n\n====\n\nAll files located in the node_modules and external directories are\nexternally maintained libraries used by this software which have their\nown licenses; we recommend you read them, as their terms may differ from\nthe terms above.\n</code></pre>"},{"location":"concepts/concepts/","title":"Framework concepts","text":""},{"location":"concepts/algorithm-components/components/","title":"List of components","text":"<p>Under construction</p>"},{"location":"concepts/algorithm-components/intro/","title":"Algorithm components","text":""},{"location":"concepts/algorithm-components/intro/#definition","title":"Definition","text":"<p>An algorithm component is any piece of code that can modify a solution in any way in the context of an optimization problem.  Algorithm components are usually implemented in classes, using a Java class per component.  Algorithm components can be classified according to their functionality and responsibility, or in other words, what is their expected behaviour.</p>"},{"location":"concepts/algorithm-components/intro/#algorithm-component-types","title":"Algorithm component types","text":"<p>Tip</p> <p>Mork provides a set of algorithm component types, which are the building blocks of any optimization algorithm. While we recommend using the provided component types, and extending the hierarchy as required, you can create your own component types hierarchy from scratch.</p> <p>All components types, and the implementations provided in the framework, are available in the <code>common</code> module. All the algorithm components provided by the framework are classified in the following roles, depending on what is expected of them.</p>"},{"location":"concepts/algorithm-components/intro/#algorithm","title":"Algorithm","text":"<p>An algorithm is a high level component which implements an strategy to generate solutions for a given problem. It must receive an instance, and return a feasible solution.</p> <p>Traditionally, algorithms have been classified in two main categories: exact and heuristic. Exact algorithms are guaranteed to find the optimal solution, while heuristic algorithms are not. Heuristic algorithms are usually faster than exact algorithms, and are used when the problem is too large to be solved exactly in a reasonable amount of time. However, they cannot usually guarantee the optimality of the solution found. Both kind of algorithms can be easily implemented, but the framework is focused on heuristic algorithms, and does not currently provide any exact algorithm implementation. An example algorithm method is GRASP, which is a heuristic algorithm that iteratively constructs a solution, and then applies an improvement method to each built solution, which is usually a best improvement or first improvement local search. Its implementation can be as simple as:</p> <pre><code>public class GRASPAlgorithm&lt;S extends Solution&lt;S, I&gt;, I extends Instance&gt; extends Algorithm&lt;S, I&gt; {\n    private static Logger log = LoggerFactory.getLogger(SimpleAlgorithm.class.getName());\n\n    protected final GRASPConstructive&lt;S, I&gt; constructive;\n    protected final Improver&lt;S, I&gt; improver;\n\n    public GRASPAlgorithm(GRASPConstructive&lt;S, I&gt; constructive, Improver&lt;S, I&gt; improver) { // (1)\n        super(\"GRASP\"); // (2)\n        this.constructive = constructive;\n        this.improver = improver;\n    }\n\n    @Override\n    public S algorithm(I instance) {\n        var solution = this.newSolution(instance); // (3)\n        solution = constructive.construct(solution);\n        Context.validate(solution); // (4)\n        solution = localSearch(solution);\n        return solution;\n    }\n\n    protected S localSearch(S solution) {\n        solution = improver.improve(solution); // (5)\n        Context.validate(solution);\n        return solution;\n    }\n}\n</code></pre> <ol> <li>Algorithms usually depend on simpler components, and ask for them via its constructor. For example the GRASPAlgorithm needs a GRASPConstructive and an improver component.</li> <li>The algorithm name is passed to the superclass constructor, which is then used for tracking its performance. Algorithm names must be unique per experiment.</li> <li>Any algorithm can create an empty solution by calling the <code>newSolution(instance)</code> method. Internally, this method will find the apropiate Java constructor and invoke it. Note that the solution is in its default state, and is probably not feasible.</li> <li>The ValidationUtil methods try to find bugs if the app is running in Validation mode, and do nothing if the app is running in Performance mode. They can be used after each algorithm step to try to find anomalous behaviour that needs to be fixed, without affecting the performance of the application. </li> <li>The localSearch method is a simple wrapper around the improver component, which is used to improve the solution. The solution is then returned.</li> </ol> <p>Algorithms implemented in the framework follow the Template Design pattern, which means that the algorithm is divided in several steps, and the steps are implemented in different methods. This allows for a high degree of code reuse, as the steps can then be implemented in different classes, or the algorithm can be easily extended by overriding the methods.</p> <p>Instead of implementing all the required functionality inside this component type, different steps are delegated to different component types, which are declared as dependencies. For example, most heuristic and metaheuristic methods need a constructive method in order to initialize feasible solutions, and usually depend on improvement components in order to get a solution to a local optima. Examples of algorithms are: Scatter Search, Genetic Algorithms, Variable Neighborhood Search and Simulated Annealing. For a full list of available components, see: Available components.</p>"},{"location":"concepts/algorithm-components/intro/#constructive","title":"Constructive","text":"<p>Constructive methods receive an empty solution and initialize it. Solutions created by constructive methods must be feasible. Commonly used constructive methods, usually easy to implement, are random and greedy approaches. A more elaborate option is using a GRASP based strategy, see GRASP inside the algorithm component list for more details about GRASP.</p>"},{"location":"concepts/algorithm-components/intro/#improver","title":"Improver","text":"<p>Improvement methods receive a feasible solutions, and try to improve its objective function score. Improver methods cannot return a solution with worse score that the input solution.  A classic example of an improver method are local search methods. Note that solutions returned from  an improvement method are not guaranteed to be optimal, but they are guaranteed to be at least as good as the input solution. Calling a local search method with a solution that is already at a local optima will return the same solution, as the local search method will not able to improve it. Note that the fact that the improvement method returns a solution, does not guarantee that the solution is cloned.  For performance reasons, the improvement method is allowed to modify the solution in place. If you want to keep a copy of the original solution, clone it by using the <code>Solution::cloneSolution</code> before calling the improvement method.</p>"},{"location":"concepts/algorithm-components/intro/#shake","title":"Shake","text":"<p>Shake methods (also called perturbation methods in the literature) are implemented similar to improvement methods, they receive and return a solution, but they are allowed to  return a solution with worse score than the input solution.  Shake methods try to scape local optima by applying an strategy that may worsen the objective function value of the given solution. Usually, this type of component is used in combination with improver methods. A common strategy found in many algorithms consists in iteratively apply a local search method to a solution, to find a local optima, and then apply a shake method to the solution, to try to scape the local optima, and then reapply the improver method.</p> <p>An example shake strategy, applicable to many optimization problems, is applying random moves to the solution, without checking if the applied moves improve or worsen the objective function value.</p> <p>Note that the fact that the shake method returns a solution, does not guarantee that the solution is cloned. For performance reasons, the shake method is allowed to modify the solution in place. If you want to keep a copy of the original solution, clone it by using the <code>Solution::cloneSolution</code> before calling the shake method.</p>"},{"location":"concepts/algorithm-components/intro/#implementing-components","title":"Implementing components","text":"<p>This section assumes that you have already created a Mork project. If you have not, please visit the Getting started section. In order to create a custom algorithm, you will need to create a new class that extends the <code>Algorithm</code> class. For example, the following code implements an algorithm that creates <code>n</code> solutions, and applies an improver method to the best solution found during the construction phase.  Note that from the point of view of the algorithm, both the constructive and improver methods are black boxes whose implementation is unknown. This principle is critical if code reusability is desired, as we could then execute it and compare the performance of our algorithm for example when using different constructive methods.</p> <p>Info</p> <p>The algorithm code contains more advanced features such as logging, time control, and metrics reporting. Although each feature is detailed in their respective page, a small summary is provided in this example.</p> <pre><code>public class MyAlgorithm&lt;S extends Solution&lt;S, I&gt;, I extends Instance&gt; extends Algorithm&lt;S, I&gt; {\n    private static Logger log = LoggerFactory.getLogger(MyAlgorithm.class));\n\n    protected final int n;\n    protected final Constructive&lt;S, I&gt; constructive;\n    protected final Improver&lt;S, I&gt; improver;\n\n    public MyAlgorithm(String algorithmName, int n, Constructive&lt;S, I&gt; constructive, Improver&lt;S, I&gt; improver) {\n        super(algorithmName);\n        this.n = n;\n        this.constructive = constructive;\n        this.improver = improver;\n    }\n\n    @Override\n    public S algorithm(I instance) {\n        var solution = constructionPhase(instance);\n        solution = localSearchPhase(solution);\n        return solution;\n    }\n\n    protected S constructionPhase(I instance){\n        var bestSolution = constructionStep(instance);\n        Metrics.add(BestObjective.class, bestSolution.getScore());\n        for (int i = 1; i &lt; n &amp;&amp; !TimeControl.isTimeUp(); i++) {\n            var solution = constructionStep(instance);\n            if(solution.isBetterThan(bestSolution)){\n                log.debug(\"Improved best solution. {} --&gt; {}\", bestSolution, solution);\n                bestSolution = solution;\n                Metrics.add(BestObjective.class, bestSolution.getScore());\n            }\n        }\n        log.debug(\"Best Construction: {}\", bestSolution);\n        return bestSolution;\n    }\n\n    protected S constructionStep(I instance){\n        var solution = this.newSolution(instance);\n        solution = constructive.construct(solution);\n        Context.validate(solution);\n        log.trace(\"New solution: {}\", solution);\n        return solution;\n    }\n\n    protected S localSearchPhase(S solution) {\n        if (TimeControl.isTimeUp()) {\n            return solution;\n        }\n        solution = improver.improve(solution);\n        Context.validate(solution);\n        Metrics.add(BestObjective.class, solution.getScore());\n        log.debug(\"After LS: {}\", solution);\n        return solution;\n    }\n\n    @Override\n    public String toString() {\n        return \"MyAlgorithm{\" +\n                \"n=\" + n +\n                \", c=\" + constructive +\n                \", i=\" + improver +\n                '}';\n    }\n}\n</code></pre> <p>Info</p> <p>Algorithms should avoid containing problem specific behaviour, delegating it to the appropriate components.</p> <p>The process is similar for any component type. See the TSP example for a guided tutorial on solving your first optimization problem using Mork.</p>"},{"location":"concepts/algorithm-components/intro/#advanced","title":"Advanced","text":"<p>One of the core design principles of the Mork framework is its flexibility. In this section, we will explain how to create custom components, and some Mork internals and design decisions. The only requirement to integrate with the framework, is using the algorithm base class.</p>"},{"location":"concepts/algorithm-components/intro/#creating-custom-types","title":"Creating custom types","text":"<p>As a rule of thumb, always use class inheritance to define the component types, and use interfaces to define its capabilities. If possible, extend the most specific existing type. However, some metaheuristic families define their own types, that may not be relevant in other metaheuristic methods. For example,</p>"},{"location":"concepts/algorithm-components/intro/#autodetect-components","title":"Autodetect components","text":"<p>Any Java class is automatically detected by the Mork engine as an algorithm component if it is either marked with the annotation <code>@AlgorithmComponent</code>, or any superclass is annotated with it (does not include interfaces).</p> <p>Tip</p> <p>Remember: all algorithm component types provided by Mork are annotated, so you do not need to use the <code>@AlgorithmComponent</code> annotation if your components extend <code>Algorithm</code>, <code>Constructive</code>, <code>Improver</code>, etc., or any other component type class.</p>"},{"location":"concepts/algorithm-components/metaheuristics/vns/","title":"Variable Neighborhood Search (VNS)","text":"<p>Variable Neighborhood Search (VNS) is a metaheuristic for solving combinatorial and global optimization problems. It systematically changes the neighborhood structure during the search to escape local optima and explore the solution space more effectively.</p>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#algorithm-outline","title":"Algorithm Outline","text":"<p>The basic VNS algorithm follows this structure:</p> <pre><code>s = GenerateInitialSolution\nwhile (termination criteria not met) {\n    k = 1\n    while (k != kmax) {\n        s' = Shake(s, k)\n        s'' = Improve(s')\n        NeighborhoodChange(s, s'', k)\n    }\n}\n</code></pre>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#how-to-use","title":"How to Use","text":""},{"location":"concepts/algorithm-components/metaheuristics/vns/#1-implement-or-select-dependencies","title":"1. Implement or select dependencies","text":"<p>You need to provide implementations for the following three components:</p> <ul> <li><code>Constructive&lt;S, I&gt;</code>: How to build an initial solution.</li> <li><code>Improver&lt;S, I&gt;</code>: How to improve a solution (for example, using a local search).</li> <li><code>Shake&lt;S, I&gt;</code>: How to perturb a solution.</li> </ul> <p>Optionally, a custom <code>VNSNeighChange&lt;S, I&gt;</code> can be used for customized neighborhood change logic.</p>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#2-build-vns-using-vnsbuilder","title":"2. Build VNS Using <code>VNSBuilder</code>","text":"<p>The recommended way to initialize and configure the VNS metaheuristic is by using a <code>VNSBuilder</code>. Example:</p> <pre><code>var vns = new VNSBuilder&lt;MySolution, MyInstance&gt;()\n        .withConstructive(new MyConstructive())\n        .withImprover(new MyImprover())\n        .withShake(new MyShake())\n        // Optionally, configure a custom neighChange method. Example: .withNeighChange(new DefaultVNSNeighChange&lt;&gt;(5, 1))\n        .withNeighChange(5) // Uses DefaultVNSNeighChange with kmax=5, increment=1\n        // Optionally: change objective to optimize from default to any other\n        // .withObjective(myCustomObjective)\n        .build(\"VNS-Config-1\");\n</code></pre>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#3-custom-neighborhood-change","title":"3. Custom Neighborhood Change","text":"<p>You can define your own neighborhood change logic by implementing <code>VNSNeighChange</code>:</p> <pre><code>VNSNeighChange&lt;MySolution, MyInstance&gt; customChange = (solution, k) -&gt; {\n    if (k &gt;= 7) return VNSNeighChange.STOPNOW;\n    return k + 2; // Increase by 2 each time\n};\n</code></pre> <p>Tip</p> <p>You can quickly implement a custom <code>VNSNeighChange</code> to control how the neighborhood change by using a lambda expression. The following example is equivalent to the default behavior of <code>DefaultVNSNeighChange</code>, with <code>max=5</code> and <code>increment=1</code>: <pre><code>.withNeighChange((solution, k) -&gt; k &gt;= 10 ? VNSNeighChange.STOPNOW : k + 1)\n</code></pre></p>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#4-implementation-notes-and-tips","title":"4. Implementation notes and tips","text":"<ul> <li>The VNS algorithm stops when the neighborhood change function returns <code>VNSNeighChange.STOPNOW</code>.</li> <li>k always starts at 0, not 1.</li> <li>The <code>DefaultVNSNeighChange</code> stops when <code>k</code> &gt;= <code>kmax</code>.</li> <li>If you want to make the VNS multistart, wrap it using the <code>MultiStartAlgorithm</code> class.</li> <li>Before each shake, the current solution is cloned to avoid worsening it. New solutions are only accepted if they improve the current score.</li> </ul>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#related-java-classes","title":"Related Java Classes","text":"<p>And links to their documentation:</p> <ul> <li><code>VNS&lt;S, I&gt;</code>: Main algorithm class. Generic in solution (<code>S</code>) and instance (<code>I</code>) types.</li> <li><code>VNSBuilder&lt;S, I&gt;</code>: Builder for configuring and instantiating VNS algorithms.</li> <li><code>VNSNeighChange&lt;S, I&gt;</code>: Functional interface for neighborhood change strategies (controls how <code>k</code> changes).</li> <li><code>DefaultVNSNeighChange&lt;S, I&gt;</code>: Default implementation of <code>VNSNeighChange</code>, increments <code>k</code> until a maximum value is reached.</li> <li><code>Constructive&lt;S, I&gt;</code>: Base class for generating initial solutions.</li> <li><code>Improver&lt;S, I&gt;</code>: Base class for any local search/improvement.</li> <li><code>Shake&lt;S, I&gt;</code>: Base class for perturbing solutions.</li> </ul>"},{"location":"concepts/algorithm-components/metaheuristics/vns/#references","title":"References","text":"<p>[1] Hansen P., Mladenovi\u0107 N. (2018) Variable Neighborhood Search. In: Mart\u00ed R., Pardalos P., Resende M. (eds) Handbook of Heuristics. Springer, Cham. DOI: 10.1007/978-3-319-07124-4_19</p>"},{"location":"examples/TSP/","title":"Step-by-step example for the Travelling Salesman Problem (TSP) with Mork","text":""},{"location":"examples/TSP/#what-is-the-travelling-salesman-problem","title":"What is the Travelling Salesman Problem?","text":"<p>The traveling salesman problem (commonly denoted as TSP) asks the following question: \"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?\" It is an NP-hard problem in combinatorial optimization, important in theoretical computer science and operations research.</p> <p></p> <p>Obtained from The Trials And Tribulations Of The Traveling Salesman .</p>"},{"location":"examples/TSP/#1-environment-set-up","title":"1. Environment set up","text":""},{"location":"examples/TSP/#11-prerequisites","title":"1.1 Prerequisites","text":"<ul> <li>Java 17 is required to run. Please download and install a recent JDK.</li> <li>Maven</li> <li>This is not really a prerequisite, but we recommend using an IDE, such as IntelliJ IDEA.</li> </ul> <p>\ud83d\udca1 Tip: Use SDKMAN to easily manage your JDKs and SDKs. Have a look to the official web page.</p>"},{"location":"examples/TSP/#12-download-problem-instances","title":"1.2 Download problem instances","text":"<p>In order to test the proposed algorithms for the TSP we will use the standard instances for the problem, that can be easily obtained from TSPLIB.</p> <p>What is TSPLIB?</p> <p>TSPLIB is a library of sample instances for the TSP  (and related problems) from various sources and of various types. Particularly, we will use the TSPLIB Symmetric Traveling Salesman Problem Instances. For the moment, you will only need to download the following files: berlin52, eil101, ch130 and st70.</p>"},{"location":"examples/TSP/#13-using-the-quick-start-project-generator","title":"1.3 Using the quick start project generator","text":"<p>Go to https://generator.mork-optimization.com/, set \"TSP\" in the Project Name field and click on generate your project. In a few seconds you will be able to download your project. Then, extract the zip file and import it in your favorite IDE.</p> <p>\ud83d\udca1 Tip:</p> <p>Some IDEs, allow you to select the <code>pom.xml</code> file when you select the option to import an existing project. If such a possibility exists, we highly recommend importing the project as a maven project. Some examples of how to import a Maven project in the most important editors can be found in: Eclipse, IntelliJ, or NetBeans.</p> <p>Remember to choose a valid name for your project, i.e., check that it starts with an Uppercase letter followed by any alphanumeric characters or underscores, without spaces.</p>"},{"location":"examples/TSP/#14-a-quick-look","title":"1.4 A quick look","text":"<p>The project is organized in the following folders</p> <ul> <li>\ud83d\udcc1 .run</li> </ul> <p>If you are using  IntelliJ, you might have noticed that there are two default configuration files: <code>Performance.run.xml</code> and <code>Validation.run.xml</code>. The main difference between both run configurations is whether the assertions are enabled. In validation mode, assertions try to check the correctness of the problem implementation, by detecting common mistakes. For more information see the specific doc page about MorK validations and the official Java documentation. You may run your own run configurations, the main class is located at <code>es.urjc.etsii.grafo.&lt;problemname&gt;.Main</code> by default.</p> <ul> <li>\ud83d\udcc1 docker :</li> </ul> <p>Docker template and helper scripts to easily build, run and deploy your application using containers. For a detailed description, see MorK containers.</p> <ul> <li>\ud83d\udcc1 instances</li> </ul> <p>This folder should contain everything related with the instances of the problem. In this case, since we are tackling the TSP, this folder will contain the TSP instances. Therefore, you should put the downloaded instances (<code>*.tsp</code> files) from TSPLIB Symmetric Traveling Salesman Problem Instances in this folder.</p> <ul> <li>\ud83d\udcc1 src/main/java/es.urjc.etsii.grafo.TSP<ul> <li>\ud83d\udcc1 algorithms: algorithmic components, i.e, constructive, local search, metaheuristics, etc.</li> <li>\ud83d\udcc1 experiments: defines experiments to execute to test the proposed algorithms and strategies.</li> <li>\ud83d\udcc1 model: contains the basic elements of the studied problem: solution, instance, etc.</li> <li>\ud83d\udcc1 drawing: helper class to draw solutions in the web frontend.</li> </ul> </li> <li>\ud83d\udcc1 src/main/resources<ul> <li>\ud83d\udcc1 irace: irace is a software package that implements a number of automatic configuration procedures.</li> <li>\ud83d\udcc1 static: contains files to generate a localhost web page which allow the researcher to see the   solution-quality convergence and the best solution found.</li> <li>\ud83d\udcdd application.yml: this file contains the global configuration of the project, such as which experiment should be   executed, which instances should be used, among others. For a detailed configuration description, see MorK configuration.</li> </ul> </li> <li>\ud83d\udcc1 src/test: similar to src/main but contains tests for the project, and related resources.</li> <li>\ud83d\udcdd .gitignore: this file tells Git which files to ignore when pushing your project to GitHub or any other remote server.</li> <li>\ud83d\udcdd pom.xml: Maven configuration file, contains the project description and its dependencies. </li> </ul>"},{"location":"examples/TSP/#2-reading-instances","title":"2. Reading instances","text":"<p>This Mork project aims to approach the Traveling Salesman Problem (TSP). Given a set of points, (that can be considered as locations or cities), the TSP consists in finding a roundtrip of minimal total length visiting each node exactly once. In this section you will learn, what an instance is, how to define an instance of the problem, and how to read an instance from a file.</p> <p>A problem instance contains all the input data needed to create solutions for a problem. Focusing on the problem at hand, an instance represents a map of cities or locations, all of them connected to each other. In this particular problem, all locations are defined by x/y coordinates.</p> <p>At this point, you should have downloaded the instance files (berlin52.tsp , eil101 , ch130 and st70), and placed them at the instance folder of the project.</p> <p>Have a look to any of those four files. The structure is the same for each of them. Particularly, these files have the  following<code>&lt;keyword&gt;:&lt;value&gt;</code> structure, where <code>&lt;keyword&gt;</code> denotes an alphanumerical keyword and <code>&lt;value&gt;</code> denotes  alphanumerical or numerical data:</p> <ul> <li>NAME : <code>&lt;string&gt;</code> // Identifies the data file.</li> <li>TYPE : <code>&lt;string&gt;</code> // Specifies the type of the data. In this case will be TSP.</li> <li>COMMENT :<code>&lt;string&gt;</code> // Additional comments.</li> <li>DIMENSION : <code>&lt;integer&gt;</code> // Number of its nodes (cities, locations, etc.)</li> <li>EDGE WEIGHT TYPE : <code>&lt;string&gt;</code> // Specifies how the edge weights (or distances) are given.</li> <li>NODE COORD SECTION :   <code>&lt;integer&gt; &lt;real&gt; &lt;real&gt;</code> // Node coordinates are given in this section.</li> </ul> <p>Notice that the five instances selected have EDGE WEIGHT TYPE = EUC_2D, which means that the distance between two points i and j is computed using the Euclidean distance: </p> \\[ {\\displaystyle d(i,j)={\\sqrt {(j_{1}-i_{1})^{2}+(j_{2}-i_{2})^{2}}}.} \\] <p>If you are interested in a deep description of the instances to test the proposed algorithm with other type of instance, have a look to the TSPLIB documentation.</p> <p>Then, open file <code>TSPInstance.java</code> located in <code>src/main/java/es/urjc/etsii/grafo/TSP/model</code>. This class will represent  an instance of the problem, i.e., a list of x/y coordinates. Therefore, we will carry out the following tasks:</p> <ul> <li>Define a structure that represents 2D coordinates.</li> <li>Define an attribute (in the <code>TSPInstance</code> class) that represents the list of locations and the distance between locations.</li> <li>Implement the class constructor and getter methods.</li> </ul> <p>Try it yourself, and compare it with our code (there is more than one possible implementation, everyone thinks different!)</p> <p>The resultant class could be something similar to:</p> <pre><code>public class TSPInstance extends Instance {  \n\n  /**  \n   * List of coordinates \n   */  \n   private final Coordinate[] locations;  \n\n\n  /**  \n   * Distance between all coordinates \n   */  \n   private final double[][] distances;  \n\n  /**  \n   * Constructor \n   * @param name name of the instance  \n   * @param locations list of coordiantes  \n   */  \n   protected TSPInstance(String name, Coordinate[] locations, double[][] distances) {  \n      super(name);  \n      this.locations = locations;  \n      this.distances = distances;  \n  }  \n\n  /**  \n   * Get the list of locations \n   * @return list of locations  \n   */  \n   public Coordinate[] getLocations() {  \n      return locations;  \n  }  \n\n  /**  \n   * Get the number of locations of the instance \n   * @return number of locations  \n   */  \n   public int numberOfLocations() {  \n      return locations.length;  \n   }  \n\n  /**  \n   * 2D coordinate \n   */  \n   public record Coordinate(double x, double y) {}  \n\n\n  /**  \n   * Get coordinate of a specific location (that represents a city, place, facility...) * * @param id of the location  \n   * @return the location coordinate  \n   */  \n   public Coordinate getCoordinate(int id) {  \n      return this.locations[id];  \n  }  \n\n\n  /**  \n   * Return the euclidean distance between two locations i and j. * * @param i first location  \n   * @param j second location  \n   * @return the euclidean distance  \n   */\n   public double getDistance(int i, int j) {  \n      return this.distances[i][j];  \n   }  \n\n}\n</code></pre> <p>\ud83d\udca1 Tip: is this the first time you have come across record? You don't know what you're missing!! Record classes, which are a special kind of class, help to model plain data aggregates with less ceremony than normal classes. Have a look to the Java documentation abut record classes.</p> <p>IMPORTANT</p> <p>After exiting the instance constructor method, the instance must be immutable. The instance class should never implement setter methods. All mutable data must be in the solution class.</p> <p>Next, lets move on to the <code>TSPInstanceImporter.java</code> file. This class responsibility is generating problem instances given some files. To this end, we will need to implement the method: <code>importInstance(BufferedReader reader, String filename)</code>.  This method receives as input parameters the buffered reader, managed by the framework, and the filename, returning the constructed instance. Considering the TSP instance file structure, we will need to read the file line by line, storing the list of coordinates and the distance between each pair of coordinates, and finally, calling the instance constructor. The resultant class will be the following:</p> <pre><code>public class TSPInstanceImporter extends InstanceImporter&lt;TSPInstance&gt; {\n\n    @Override\n    public TSPInstance importInstance(BufferedReader reader, String filename) throws IOException {\n        Scanner sc = new Scanner(reader).useLocale(Locale.US);\n        String name = sc.nextLine().split(\":\")[1].trim();\n        String type = sc.nextLine().split(\":\")[1];\n        String comment = sc.nextLine().split(\":\")[1];\n        int dimension = Integer.parseInt(sc.nextLine().split(\":\")[1].trim());\n        String edgeWeightType = sc.nextLine().split(\":\")[1];\n        String nodeCoordSection = sc.nextLine();\n        TSPInstance.Coordinate[] locations = new TSPInstance.Coordinate[dimension];\n        while (!sc.hasNext(\"EOF\")) {\n            int id = sc.nextInt() - 1;\n            double x = sc.nextDouble();\n            double y = sc.nextDouble();\n            locations[id] = new TSPInstance.Coordinate(x, y);\n        }\n        double[][] distances = getMatrixOfDistances(locations);\n        return new TSPInstance(name, locations, distances);\n    }\n\n\n    /**\n     * Calculate all euclidean distances between all locations\n     *\n     * @param locations list of locations\n     * @return a matrix of distances\n     */\n    private double[][] getMatrixOfDistances(TSPInstance.Coordinate[] locations) {\n        var dimension = locations.length;\n        double[][] distances = new double[dimension][dimension];\n        for (int i = 0; i &lt; dimension; i++) {\n            for (int j = i+1; j &lt; dimension; j++) {\n                var distance = this.calculateEuclideanDistance(locations[i], locations[j]);\n                distances[i][j] = distance;\n                distances[j][i] = distance;\n            }\n        }\n       return distances;\n    }\n\n\n    /**\n     * Calculate the Euclidian distance of two given coordinates\n     *\n     * @param i first coordinate\n     * @param j second coordinate\n     * @return the euclidean distance between two coordiantes\n     */\n    public double calculateEuclideanDistance(TSPInstance.Coordinate i, TSPInstance.Coordinate j) {\n        var di = i.x() - j.x();\n        var dj = i.y() - j.y();\n        return Math.sqrt((di * di) + (dj * dj));\n    }\n}\n</code></pre> <p>\ud83d\udca1 Tip: You may use the BufferedReader as given,  or initialize a Scanner from the BufferedReader.  However, both approaches cannot be used at the same time  (i.e, sometimes reading from the buffered reader and sometimes from the scanner),  as it may result in missing input data.</p>"},{"location":"examples/TSP/#3-modelling-solution","title":"3. Modelling solution","text":"<p>The next task is to define the TSP solution class. Solution classes contain mutable data that is modified while solving an instance.  In the case of the TSP, the solution contains the order in which we will visit each of the cities or locations. To define a solution in Mork we must edit the <code>TSPSolution</code> class. The objects of this class represent the candidate solutions that are handled throughout the optimization algorithm developed. The simplest implementation of a circular path is through an array of integers, where the index represents the order (or position) in the path of the location (identified by the ID) referenced by that array index. While in this example we use an array, as we must visit all locations and therefore the size is known, other times other data structures such as <code>HashSet</code> or <code>ArrayList</code> may be more appropriate.  Choosing the most performant data structure is not trivial, and sometimes the most performant approach is using an unexpected data structure.  Different alternatives can be tested and benchmarked to find the most efficient one.</p> <pre><code>/**\n * Cached length of the path between all locations, for performance reasons\n */\nprivate double distance;  \n\n/**\n * Order of the locations in the path. \n * The index represents the position in the path, and the value the location ID.\n */\nprivate final int[] route;\n</code></pre> <p>The main methods of the <code>TSPSolution</code> class are the following:</p>"},{"location":"examples/TSP/#constructors","title":"Constructors","text":"<p>By default, two constructors must be implemented. The first one initializes a solution given an instance. The second one initializes a solution given another solution, and it is used for cloning data. For example:</p> <pre><code>public TSPSolution(TSPInstance instance) {  \n  super(instance);  \n  this.route = new int[instance.numberOfLocations()];  \n  Arrays.fill(route, -1);  // -1 means that the position is empty / unused\n}\n\npublic TSPSolution(TSPSolution s) {  \n   super(s);  \n   this.route = s.route.clone();  \n   this.distance = s.distance;  \n}\n</code></pre>"},{"location":"examples/TSP/#objective-function-methods","title":"Objective function methods","text":"<p>We will also need a method to calculate the objective function of the solution. Usually, two different methods are implemented:</p> <ul> <li><code>public double getScore()</code> : get the objective function of the solution. This procedure may behave like a getter method, returning cached score without performing any calculation.</li> <li><code>public double recalculateScore()</code>: recalculate solution objective function. Make sure this method does not have side effects (a common mistake is updating caches while executing recalculateScore). If this method does have side effects, something that may happen is that two subsequent calls to <code>recalculateScore()</code> may return different results.</li> </ul> <p>In this case, the objective function is the total distance of the path. Therefore, the implementation of these methods is <pre><code>public double getScore() {  \n   return this.distance;  \n}\n\npublic double recalculateScore() {  \n   double distance = 0;  \n   for (int i = 0; i &lt; this.route.length; i++) {  \n      var j = (i + 1) % this.route.length;  \n      distance += this.getInstance().getDistance(route[i], route[j]);  \n  }  \n  return distance;  \n}\n</code></pre> Note that the <code>recalculateScore()</code> method is not updating the distance attribute, but returning the calculated value. Moreover, both method names can be changed to <code>getDistance()</code> and <code>recalculateDistance()</code> respectively, to better reflect the nature of the problem.</p> <p>Why have two implementations?</p> <p>The first method should be used when the solution is not modified, and the objective function is requested.  This way, the objective function is calculated only once, and the result is cached. The second method is used when the solution is modified, and the objective function must be recalculated. In the next section, we will see how to update the objective function when the solution is modified incrementally.</p>"},{"location":"examples/TSP/#move-methods","title":"Move methods","text":"<p>While the solution class may contain all the necessary methods to operate and edit a solution, when the number of possible operations increases we can end with an extremely big, complex and unmaintainable class. In this case, we can split the solution class into different classes, each one containing a set of operations. For example, we can create a class responsible for inserting new nodes, and another one for swapping nodes (exchange the order of two locations, classic interchange movement), etc.</p> <p>In this example, we will implement all required methods inside the solution class, and in a later section we will refactor the code to use neighborhoods and movements. swap and insert movements.  <pre><code>   /**  \n    * Shuffle route \n    */\n    public void shuffleRoute() {  \n       ArrayUtil.shuffle(route);  \n    }  \n\n\n    /**  \n     * Swap classical move: \n     * Swap the position in the route of two locations, given its actual positions. \n     * Example: actual route : [a,b,c,d,e,f], pi = 0,  pj= 1, resultant route= [b,a,c,d,e,f] \n     * Example: actual route : [a,b,c,d,e,f], pi = 1,  pj= 4, resultant route= [a,e,c,d,b,f] \n     * When the operation is performed, the objective function (this.distance) is updated\n     * @param pi actual position of the location  \n     * @param pj desired position  \n     */\n     public void swapLocationOrder(int pi, int pj) {  \n        var i = this.route[pi];  \n        var j = this.route[pj];  \n        this.distance = this.distance - getDistanceContribution(pi) - getDistanceContribution(pj);  \n        this.route[pi] = j;  \n        this.route[pj] = i;  \n        this.distance = this.distance + getDistanceContribution(pi) + getDistanceContribution(pj);  \n    }  \n\n\n    /**  \n     * Insert classical move: \n     * Deletes a location from and array (given its position) and inserts it in the specified position. \n     * Example: actual route : [a,b,c,d,e,f], pi = 0,  pj= 1, resultant route= [b,a,c,d,e,f] \n     * Example: actual route : [a,b,c,d,e,f], pi = 1,  pj= 4, resultant route=[a,c,d,e,b,f] \n     * Example: actual route : [a,b,c,d,e,f], pi = 5   pj= 3, resultant route= [a,b,c,f,d,e] \n     * When the operation is performed, the objective function (this.distance) is updated * \n     * @param pi actual position of the location  \n     * @param pj desired position  \n     */\n     public void insertLocationAtPiInPj(int pi, int pj) {  \n        ArrayUtil.deleteAndInsert(this.route, pi, pj);  \n        this.distance = this.recalculateScore();  \n    }\n</code></pre></p> <p>Tip</p> <p>Take a look at the Javadocs of the util classes such as <code>CollectionUtil</code> and <code>ArrayUtil</code>, they may contain commonly used methods that are not implemented in the Java API. Are you missing some methods? Open an issue or submit a pull request!</p>"},{"location":"examples/TSP/#4-our-first-algorithms-and-experiments","title":"4. Our first algorithms and experiments","text":"<p>In this section we will generate our first solutions for the TSP. To do so, we will perform the following tasks:</p> <ol> <li>Implement a constructive that generates random solutions.</li> <li>Define an experiment.</li> <li>Run Mork: understanding the application.yml, the web interface and results.</li> </ol>"},{"location":"examples/TSP/#constructive-procedures","title":"Constructive procedures","text":"<p>Constructive procedures are methods that generate solutions to a problem. To implement a constructive we are going to use as an example the constructive procedure located in the <code>constructives</code> folder. Every constructive proposed for the TSP must extend <code>Constructive&lt;TSPSolution, TSPInstance&gt;</code>.</p> <p>A simple implementation of a randomized constructive is shown below:</p> <pre><code>    @Override\n    public TSPSolution construct(TSPSolution solution) {\n        for (int i = 0; i &lt; solution.getInstance().numberOfLocations(); i++) {\n            solution.setOrderOfLocation(i, i);\n        }\n        solution.shuffleRoute();\n        solution.notifyUpdate();\n        solution.setScore(solution.recalculateScore());\n        return solution;\n    }\n</code></pre>"},{"location":"examples/TSP/#define-an-experiment","title":"Define an experiment","text":"<p>Once the constructive procedure has been defined, let's define an experiment. Each of the experiments to be executed for the TSP should be located in the 'experiments' folder and must extend the <code>AbstractExperiment&lt;TSPSolution, TSPInstance&gt;</code> class. To define an experiment it is necessary to implement the method <code>getAlgorithms()</code>; which returns a list of algorithms. In this case, we are only interested in testing a simple algorithm, a constructive procedure. Therefore, the resulting experiment would look like this:</p> <pre><code>public class ConstructiveExperiment extends AbstractExperiment&lt;TSPSolution, TSPInstance&gt; {\n\n    private final TSPConfig config;\n\n    public ConstructiveExperiment(SolverConfig solverConfig) {\n        this.config = solverConfig;\n    }\n\n    @Override\n    public List&lt;Algorithm&lt;TSPSolution, TSPInstance&gt;&gt; getAlgorithms() {\n\n        var algorithms = new ArrayList&lt;Algorithm&lt;TSPSolution, TSPInstance&gt;&gt;();\n\n        algorithms.add(new SimpleAlgorithm&lt;&gt;(new TSPRandomConstructive()));\n\n        return algorithms;\n    }\n}\n</code></pre>"},{"location":"examples/TSP/#run-mork","title":"Run Mork","text":"<p>Before running Mork we need to review its configuration and check that they are correct. To do so, go to <code>application.yml</code> file, located at <code>src/main/resources/</code>. This file contains a list of well-documented properties. In this case we are going to focus just on some of them:</p> <ul> <li><code>instances.path</code>: in this property the path of the location of the instances should be indicated (either a specific instance or a folder of instances, or even a folder with folders of instances). It is possible to indicate a path for each   experiment. In this case we set <code>default: 'instances'</code>.</li> <li><code>solver.experiments</code>: this property determines which experiment or experiments should be executed. To do so, you can optionally use   a regex expression. For a single experiment execution, just specify the class name: <code>experiments: 'ConstructiveExperiment'</code>. </li> <li><code>solver.parallelExecutor</code>, <code>solver.nWorkers</code>: these properties determine the maximum of workers that will be used to execute the experiments.</li> </ul> <p>Have a look to the rest of configuration parameters and feel free to change whatever you want.  A more detailed explanation of how configuration works can be found at this link.</p> <p>Now we are ready to execute. Use your IDE to run the provided main method, IntelliJ should autodetect and create two configurations (Validation and Performance). You will see a lot of text and numbers in the console, don't worry, you can analyze them carefully when the program finishes, it is not difficult to understand. While the algorithm is running, go to: http://localhost:8080/. In that website, you will be able to visualize the convergence chart and the actual value chart for each of the instance executed. In addition, you will be able to visualize the best solution found (as soon as we learn how to do it in the next sections).</p> <p>\ud83d\udca1 Tip: when all experiments finish, the web server stops. If you wish to keep the webserver running, set: <code>event.webserver.stopOnExecutionEnd: false</code> in the application.yml file.</p> <p>When the execution ends, go to the results folder and check that an Excel file (*.xlsx) has been correctly generated. The Excel file contains two sheets: a summary of the results and raw results. Particularly, the summary file should report the following data (exactly the same, Mork experiments are fully reproducible)</p> ScTSPRandomConstructive Instance names Min. score Sum Total T(s) hasBest Min. %Dev2Best berlin52 25944.86163 0.002271 1 0 ch130 42393.82045 0.0022626 1 0 eil101 3094.175908 0.0024924 1 0 st70 3285.619063 0.0015071 1 0"},{"location":"examples/TSP/#local-searches","title":"Local Searches","text":"<p>In this section you will be able to implement local search procedures and define more complex experiments. A local search algorithm starts from a candidate solution and then iteratively moves to a neighbor solution. As an example, we will define to classical neighborhood based on the swap and insert movement. To this end, we will perform the following tasks:</p> <ol> <li>Implement a neighborhood structure.</li> <li>Implement the insert/swap operator.</li> <li>Define a Local Search experiment.</li> </ol>"},{"location":"examples/TSP/#implement-a-neighborhood-structure","title":"Implement a neighborhood structure","text":"<p>A neighborhoods represents all potential solutions that can be reached for a given solution applying a movement. In general, Neighborhoods can be explored using two different strategies:</p> <ol> <li>Eager exploration: Movements in this neighborhood are generated at once, using a list (<code>List&lt;&gt;</code>) of EagerMoves. Convenient, but may waste computer resources when the improve method is not a best improvement approach.</li> <li>Lazy exploration:  Movements in this neighborhood are generated lazily under demand using <code>Streams</code> with Moves. Generate moves only when they need to be evaluated.</li> </ol> <p>Insert neighborhood</p> <p>To better explain eager exploration we are going to use the Insert classical move as an example. The insert operator consist in removing a location from the route and insert it between other two locations (i.e., insert it at a specific position).</p> <p>Have a look to the example depicted in the figure above. The location with ID=7 has been removed from the route, and it is wanted to insert it between locations 2 and 3. The resulting route after the insertion is shown in the second array. </p> <p>Given the insert operator, the neighborhood is defined as all possible insertions of all locations in any position of the route. To this end, we first create a class named: <code>InsertNeighborhood</code> that must extend <code>Neighborhood&lt;InsertNeighborhood.InsertMove, TSPSolution, TSPInstance&gt;</code>, and where <code>InsertNeighborhood.InsertMove</code>is the insert move operator we have to define. Once the header of the class has been defined, next task will be to implement the method <code>public ExploreResult&lt;...&gt; explore(TSPSolution solution)</code>.  This method will generate all possible insert moves given a solution (i.e., insert all locations in each of the positions of the route). A straightforward implementation is shown below:</p> <pre><code>    @Override\n    public ExploreResult&lt;InsertMove, TSPSolution, TSPInstance&gt; explore(TSPSolution solution) {\n        List&lt;InsertMove&gt; list = new ArrayList&lt;&gt;();\n        for (int i = 0; i &lt; solution.getInstance().numberOfLocations(); i++) {\n            for (int j = 0; j &lt; solution.getInstance().numberOfLocations(); j++) {\n                list.add(new InsertMove(solution, i, j));\n            }\n        }\n        return new ExploreResult&lt;&gt;(list);\n    }\n</code></pre> <p>Next task is to implement the Insert move: <code>public static class InsertMove extends TSPBaseMove</code>. Notice that this class has been nested inside the <code>InsertNeighborhood</code> class. As you may have noticed, the constructor of an insert move receive tree parameters: the solution and two integers: the position in the route of the location to insert in a desired position. Regardless of the type of movement intended, the following methods have to be implemented:</p> <ul> <li><code>TSPSolution _execute()</code>: execute the move, returning the modified solution. In our case, the solution will be modified in place.</li> <li><code>double getValue()</code>: or any other method, as longs as it returns how much the score is going to change if this movements is applied to the solution. procedure calculates the difference between the value of the solution that would be obtained   if the movement were carried out, and the value of the current target solution. </li> <li>The easiest implementation of this class is depicted below.</li> </ul> <pre><code>    public static class InsertMove extends TSPBaseMove {\n\n        final int pi;\n        final int pj;\n\n        /**\n         * Constructor on an insert move. Given a solution, an insert move consist in inserting the the location of a position pi, into a position pj.\n         *\n         *\n         * @param solution current solution\n         * @param pi position of the location is going to be inserted into pj\n         * @param pj position where the location of pi is going to be inserted\n         */\n        public InsertMove(TSPSolution solution, int pi, int pj) {\n            super(solution);\n            this.pi = pi;\n            this.pj = pj;\n            this.distanceDelta = calculateValue(solution);\n        }\n\n        @Override\n        protected TSPSolution _execute(TSPSolution solution) {\n            solution.insertLocationAtPiInPj(pi, pj);\n            return solution;\n        }\n\n        private double calculateValue(TSPSolution solution){\n            var s = solution.cloneSolution();\n            s.insertLocationAtPiInPj(pi, pj);\n            return s.getDistance() - solution.getDistance();\n        }\n</code></pre> <p>In this example, <code>getValue()</code> performed the insert move in a cloned solution of the current one. Then it returns the difference in the objective function value between the cloned one (the neighbor solution) and the current one. This procedure is extremely inefficient. An efficient way to perform this calculation will evaluate just the part of the solution that has changed after the move. We depict a more efficient approach in the swap move example.</p> <p>Swap neighborhood</p> <p>Movements in this neighborhood are generated lazily under demand using <code>Streams</code>. In this neighborhood we will need to build an exhaustive stream to iterate over it. We will use the classical swap move operator to define a Lazy Neighborhood. This move, exchange the position in the route of two locations, and can be easily explained through the following picture.</p> <p></p> <p>The main difference between this neighborhood and the previous one is the way in which the movements are defined. In this case, instead of generating a list of movements, we will define a Stream. The general idea of this neighborhood is that given a movement,  the next movement can be generated (if it exists). In this way, movements are only generated if they are needed. How to do it? First, we generate the Swap Neighborhood class (<code>SwapNeighborhood extends Neighborhood&lt;SwapNeighborhood.SwapMove, TSPSolution, TSPInstance&gt;</code>) and implement the explore method. This method need to generate only the initial <code>SwapMove</code> object.</p> <pre><code>    public class SwapNeighborhood extends Neighborhood&lt;SwapNeighborhood.SwapMove, TSPSolution, TSPInstance&gt; {\n\n\n    @Override\n    public ExploreResult&lt;SwapMove, TSPSolution, TSPInstance&gt; explore(TSPSolution solution) {\n        // Instead of using a double for loop like the insert, we are going to generate the movements lazily\n//        List&lt;SwapMove&gt; swapMoves = new ArrayList&lt;&gt;();\n//        for (int i = 0; i &lt; solution.getInstance().numberOfLocations(); i++) {\n//            for (int j = i + 1; j &lt; solution.getInstance().numberOfLocations(); j++) {\n//                swapMoves.add(new SwapMove(solution, i, j));\n//            }\n//        }\n//        return ExploreResult.fromList(swapMoves);\n\n        int nLocations = solution.getInstance().numberOfLocations();\n        var stream =\n                // Generate all possible swap origin point, from 0 to n-1\n                IntStream.range(0, nLocations-1).boxed()\n                        // For each origin point, generate all possible swap destination points: from starting point + 1 to n\n                        .flatMap(i -&gt; IntStream.range(i + 1, nLocations).mapToObj(j -&gt; new SwapMove(solution, i, j)));\n\n        int streamSize = nLocations * (nLocations - 1) / 2;\n        return ExploreResult.fromStream(stream, streamSize);\n    }\n\n    public static class SwapMove extends TSPBaseMove {\n\n        final int nLocations;\n        final int pi;\n        final int pj;\n\n        public SwapMove(TSPSolution solution, int pi, int pj) {\n            super(solution);\n            this.nLocations = solution.getInstance().numberOfLocations();\n            this.pi = pi;\n            this.pj = pj;\n            this.distanceDelta = calculateValue(solution);\n        }\n\n        private double calculateValue(TSPSolution solution) {\n            var s = solution.cloneSolution();\n            s.swapLocationOrder(pi, pj);\n            return s.getDistance() - solution.getDistance();\n        }\n\n        @Override\n        protected TSPSolution _execute(TSPSolution solution) {\n            solution.swapLocationOrder(pi, pj);\n            return solution;\n        }\n\n        @Override\n        public String toString() {\n            return String.format(\"Swap %s &lt;-&gt; %s\", this.pi, this.pj);\n        }\n        // Omitted hashcode and equals generated by IntelliJ\n    }\n}\n</code></pre> <p>An example of the stream generated by this procedure, given an instance with locations A, B, C, D and E, starting with the swap A &lt;-&gt;B, will be the following: A &lt;-&gt; B, A &lt;-&gt; C, A &lt;-&gt; D, A &lt;-&gt; E, B &lt;-&gt; C, B &lt;-&gt; D, B &lt;-&gt; E, C &lt;-&gt; D, C &lt;-&gt; E, D &lt;-&gt; E, and finally, <code>null</code>.</p>"},{"location":"examples/TSP/#local-search-experiments","title":"Local Search experiments","text":"<p>Defining a local search experiment is as easy as defining a constructive experiment. Copy the <code>ConstructiveExperiment</code> class in the same folder and rename it to <code>LocalSearchExperiment</code>. In Mork, there are already implemented two different type of local searches: <code>LocalSearchFirstImprovement</code> and <code>LocalSearchBestImprovement</code>. The first one follows a first improvement strategy, i.e., as soon as it finds a move that results on an improvement, it is executed. The second one follows the best improvement strategy, it explores all solutions of a neighborhood and execute the best possible move, the move that results in the best solution of the neighborhood. In this experiment we are going to define 5 algorithms:</p> <ul> <li>Random constructive:</li> <li>Insert Neighborhood following a first and best improvement strategy</li> <li>Swap Neighborhood following a first and best improvement strategy</li> </ul> <pre><code>public List&lt;Algorithm&lt;TSPSolution, TSPInstance&gt;&gt; getAlgorithms() {  \n  var algorithms = new ArrayList&lt;Algorithm&lt;TSPSolution, TSPInstance&gt;&gt;();\n  algorithms.add(new SimpleAlgorithm&lt;&gt;(\"Random\", new TSPRandomConstructive()));  \n  algorithms.add(new SimpleAlgorithm&lt;&gt;(\"Random-FI-Insert\", new TSPRandomConstructive(),new LocalSearchFirstImprovement&lt;&gt;(super.isMaximizing(), new InsertNeighborhood())));  \n  algorithms.add(new SimpleAlgorithm&lt;&gt;(\"Random-BI-Insert\", new TSPRandomConstructive(),new LocalSearchBestImprovement&lt;&gt;(super.isMaximizing(), new InsertNeighborhood())));  \n  algorithms.add(new SimpleAlgorithm&lt;&gt;(\"Random-FI-Swap\", new TSPRandomConstructive(),new LocalSearchFirstImprovement&lt;&gt;(super.isMaximizing(), new SwapNeighborhood())));  \n  algorithms.add(new SimpleAlgorithm&lt;&gt;(\"Random-BI-Swap\", new TSPRandomConstructive(),new LocalSearchBestImprovement&lt;&gt;(super.isMaximizing(), new SwapNeighborhood())));  \n  return algorithms;\n}\n</code></pre> <p>Now is the moment to run this new experiment. Change the experiment property in the <code>application.yml</code> file and run it! Remember to look to the interactive dashboard run in localhost. Which is the best algorithm?</p>"},{"location":"examples/TSP/#5-visualizing-solutions","title":"5. Visualizing solutions","text":"<p>Danger</p> <p>This section is outdated, and will be rewritten soon using the new frontend and API. We recommend to skip this section for now.</p> <p>In some cases you may be interested in seeing the solutions you are generating with your algorithms. This may allow you to detect possible problems, such as errors in the calculation of the objective function, or to detect weaknesses of the proposed methods.</p> <p>This can be easily done with Mork. First, you have to look for a program/software to represent the solution you are generating. Particularly, in the case of the TSP, a solution of the problem represents a circular route that cover a set of locations.</p> <p>A simple, easy and open source software to visualize graph is Graphviz. Graph visualization is a way of representing structural information as diagrams of abstract graphs and networks. There are many other cool libraries you could use to visualize graphs such as Highcharts ,Chart.js or D3.js, among others. For the moment, Graphviz is enough.</p> <p>All methods needed to draw a solution are located in <code>/drawing/DotGenerator.java</code>. We are not going to focus on how the graph is generated. We recommend the interested reader to have a look to Graphviz documentation. An example Graphviz diagram of a solution for the instance berlin52 is illustrated in the following figure. Additionally, the source code that generates that figure can be found here.</p> <p></p> <p>Next task is to generate that figure each time a new best solution is found. Obviously, we want to show that figure in the dashboard launched in http://localhost:8080/. To do so, you will need to have just a bit of knowledge of javascript. Therefore, go to <code>resources/static/app.js</code> and complete two methods: <code>function onSolutionGenerated(event)</code> and  <code>function onInstanceProcessingStart(event)</code>.</p> <pre><code>function onInstanceProcessingStart(event) {\n    [...]\n    // Draw best solution found\n    $('.best-solutions').prepend(\"&lt;div id='best-solution-\" + instanceName + \"' class='text-center box-rendered-solution'&gt;&lt;/div&gt;\");\n    bestValue = NaN;\n    current_best_sol = $('#best-solution-' + instanceName);\n     [...]\n}   \n\nfunction onSolutionGenerated(event) {\n    [...]    \n    // Change to &gt; if maximizing\n    if (isNaN(bestValue) || event.score &lt; bestValue) {\n        const chart_to_update = current_best_sol;\n        bestValue = event.score;\n        $.get(\"/api/generategraph/\" + event.eventId, (response) =&gt; {\n            chart_to_update.html(` &lt;p class=\"text-center\"&gt; best solution is ${event.score}&lt;/p&gt;` +\n                `&lt;img class=\"rendered-solution\" src=\"data:image/png;base64,${response}\" /&gt;`\n            );\n        });\n    }\n    [...]\n}\n</code></pre> <p>Now it is time to execute again or Local Search experiment and analyse how the solution and the solution quality evolves over the time. The result should be similar than the following image:</p> <p></p>"},{"location":"examples/TSP/#6-irace","title":"6. Irace","text":"<p>Danger</p> <p>This section is outdated, and will be rewritten soon using the new Autoconfig module. We recommend to skip this section for now, and ask for support if necessary.</p> <p>In short, Irace is a software package that implements a number of automatic configuration procedures, that allows us to easily tune our algorithms when manually testing each possible configuration is not viable. Irace is integrated in Mork, so tuning your algorithms is extremely easy. More information in the guidelines provided in the published article: \"The irace package: Iterated racing for automatic algorithm configuration\" , or in the irace package documentation: \"The irace Package: User Guide\" .</p> <p>To implement irace, please, have a look to the documentation for further details. Anyway, in this section, we will explain how to implement irace for the TSP. Particularly, we will generate an experiment to determine which is the best local search for the TSP: First or Best improvement local search, and Insert or Swap Neighborhood.</p> <ol> <li>Configure an irace experiment.</li> <li>Define the parameters to test.</li> <li>Adjusting scenario options.</li> </ol>"},{"location":"examples/TSP/#configure-an-irace-experiment","title":"Configure an irace experiment","text":"<p>To configure an irace experiment it is needed to create a class that extends <code>IraceAlgorithmGenerator&lt;TSPSolution, TSPInstance&gt;</code>. In a Mork project, just one class, and only one, can extend <code>IraceAlgorithmGenerator</code>.</p> <p>This class must implement the method <code>public Algorithm&lt;TSPSolution, TSPInstance&gt; buildAlgorithm(IraceRuntimeConfiguration config)</code>, in charge of generate an Algorithm based on <code>IraceRuntimeConfiguration</code> object. This object contains the configuration of the experiment and will be defined in the next section. To obtain the configuration parameter, the method <code>String getValue(String s)</code> have to be called. In this case, two parameters has to be defined: the strategy of the local search (first or best); and the neighborhood (insert or swap).</p> <pre><code>public class IraceExperiment extends IraceAlgorithmGenerator&lt;TSPSolution, TSPInstance&gt; {\n\n    @Override\n    public Algorithm&lt;TSPSolution, TSPInstance&gt; buildAlgorithm(IraceRuntimeConfiguration config) {\n\n        var localSearchName = config.getValue(\"localsearch\").orElseThrow();\n        var localSearchStrategy = config.getValue(\"localSearchStrategy\").orElseThrow();\n        var localSearch = buildLocalSearch(localSearchName, localSearchStrategy);\n        var constructive = new TSPRandomConstructive();\n        return new SimpleAlgorithm&lt;&gt;(constructive, localSearch);\n    }\n\n\n    private LocalSearch&lt;? extends Move&lt;TSPSolution, TSPInstance&gt;, TSPSolution, TSPInstance&gt; buildLocalSearch(String localSearchName, String localSearchStrategy) {\n\n        var neighborhood = switch (localSearchName) {\n            case \"insert\" -&gt; new InsertNeighborhood();\n            case \"swap\" -&gt; new SwapNeighborhood();\n            default -&gt; throw new IllegalArgumentException(\"Not implemented: \" + localSearchName);\n        };\n\n        return switch (localSearchStrategy) {\n            case \"first\" -&gt; new LocalSearchFirstImprovement&lt;&gt;(false, neighborhood);\n            case \"best\" -&gt; new LocalSearchBestImprovement&lt;&gt;(false, neighborhood);\n            default -&gt; throw new IllegalArgumentException(\"Not implemented: \" + localSearchStrategy);\n        };\n    }\n}\n</code></pre>"},{"location":"examples/TSP/#define-the-parameters-to-test","title":"Define the parameters to test","text":"<p>Go to file <code>/resources/irace/parameters.txt</code>  and include at the end the two following lines:</p> <pre><code>## Configuration of the local searches\nlocalsearch \"localsearch=\" c (swap, insert)\nlocalSearchStrategy \"localSearchStrategy=\" c (first, best)\n</code></pre> <p>As you might have noticed, <code>localsearch</code> and <code>localSearchStrategy</code> matches with the lines:</p> <pre><code>var localSearchName = config.getValue(\"localsearch\").orElseThrow();\nvar localSearchStrategy = config.getValue(\"localSearchStrategy\").orElseThrow();\n</code></pre> <p>Be sure that you leave some empty lines at the end of the file (we don't why it crashes if there are no lines)</p>"},{"location":"examples/TSP/#adjusting-scenario-options","title":"Adjusting scenario options","text":"<p>Next, go to <code>/resources/irace/scenario.txt</code> and read carefully all configuration parameters. Some parameters you could modify are: <code>trainInstancesDir</code>, <code>maxExperiments</code>, <code>targetRunnerParallel</code>, among others.</p>"},{"location":"examples/TSP/#execute-irace","title":"Execute irace","text":"<p>To execute irace, first, go to <code>application.yml</code> and enable irace:</p> <pre><code># Enable irace integration? Check IRACE Wiki section before enabling\nirace:\nenabled: false\n\n# False: use GraalVM implementation, does not need R installed locally\n# True: Use shell to execute R scripts, R/Rscript need to be locally installed and in path\nshell: true\n</code></pre> <p>Now, it's the moment when you wait up to a few hours until it ends. The time it takes to find the best configuration depends on the number of instances specified, as well as it sizes and the number of experiments that will be carried out. After it finishes, you may see something similar to:</p> <pre><code># Best configurations (first number is the configuration ID; listed from best to worst according to the sum of ranks):\n localsearch localSearchStrategy\n 2       insert               first\n [...]\n</code></pre> <p>Great! Irace has determined that the best neighborhood strategy was 'First improvement', exploring the neighborhood of the inserts. These results are consistent with our experimentation.</p>"},{"location":"examples/TSP/#did-you-use-irace","title":"Did you use irace?","text":"<p>Please, do not forget to cite the original paper where Manuel L\u00f3pez-Iba\u00f1ez et al. published it:</p> <pre><code>L\u00f3pez-Ib\u00e1\u00f1ez, M., Dubois-Lacoste, J., C\u00e1ceres, L. P., Birattari, M., &amp; St\u00fctzle, T. (2016). The irace package: Iterated\nracing for automatic algorithm configuration. Operations Research Perspectives, 3, 43-58.\n</code></pre>"},{"location":"examples/TSP/#7-testing-in-mork","title":"7. Testing in Mork","text":""},{"location":"examples/TSP/#asserts","title":"Asserts","text":"<p>I'm sure you've spent hours in front of your code trying to find that \ud83e\udd2c bug. For that reason, we consider that it is important that any operation must be validated, and check that the implemented procedures perform the desired behavior. And how can this be done in Mork? There are many ways, testing is one way, but in this case, we are talking about asserts. The keyword or reserved word assert is used to state that at a certain point in the code a certain condition must be true. For example, if you write a method that calculates the speed of a particle, you might assert that the calculated speed is less than the speed of light. Not using it yet? Take a look at the official documentation and start using it right now. Experience has shown that writing assertions while programming is one of the quickest and most effective ways to detect and correct bugs. As an added benefit, assertions serve to document the inner workings of your program, enhancing maintainability. By default, assertions are disabled at runtime. To enable assertions use the <code>-enableassertions</code>, or <code>-ea</code>, as a program argument.</p>"},{"location":"features/compare/","title":"State-of-the-Art comparison","text":"<p>Usually, we have a set of reference results for a given set of instances, maybe because the optimal value is known, or maybe a previous heuristic approach.</p> <p>We can feed this existing data to Mork so it is automatically taken into account when comparing different algorithmic approaches, for example, when the Excel files are generated, best values and deviation to best known values are calculated taking into account this existing data. In the Mork context, this values, which may include objective function values, execution times, etc, are called Reference Results.</p>"},{"location":"features/compare/#programmatically-feeding-reference-data","title":"Programmatically feeding reference data","text":"<p>In order to feed this data to the framework, extend the class <code>ReferenceResultProvider</code>, and implement the method <code>ReferenceResult getValueFor(String instanceName)</code>. Example:</p> <pre><code>/**\n * SOTA results using an Integer Linear : Loads reference results as reported in http://dx.doi.org/10.10...\n */\npublic class MyProblemReferenceResults extends ReferenceResultProvider {\n\n    private Map&lt;String, ReferenceResult&gt; sotaResults = new HashMap&lt;&gt;();\n\n    /**\n     * Load reference values from TSV or CSV file\n     * The file format in this example is \"instanceName,functionValue,executionTime\",\n     * so after the split by ',', instance name is in position 0, f.o value in position 1, and lastly execution time in position 2.\n     */\n    public MyProblemReferenceResults() {\n        Files.lines(Path.of(\"sota.csv\"))\n                //.skip(1) // Remember to skip the first line if the file has headers\n                .forEach(l -&gt; {\n                    var parts = l.split(\",\"); // Examples of separators are: ';', ',' or '\\t', depending on your files\n                    var referenceResult = new ReferenceResult();\n                    referenceResult.setScore(parts[1]);\n                    // If the value comes from an exact algorithm, you may mark it as optimal\n                    // The framework will validate that no solution improves this result, as it would be a bug\n                    // optimalValue defaults to false if not specified\n                    // referenceResult.setOptimalValue(true);\n                    referenceResult.setTimeInSeconds(parts[2]); // If the time value is a TimeToBest, use setTimeToBest*\n                    sotaResults.put(parts[0], referenceResult);\n                });\n    }\n\n    /**\n     * It is \n     * @param instanceName Get ReferenceResult for the given instance\n     * @return Reference value for the instance if known, or empty reference result if not. \n     * It is perfectly valid to not have all values for all instances.\n     */\n    @Override\n    public ReferenceResult getValueFor(String instanceName) {\n        return this.sotaResults.getOrDefault(instanceName, new ReferenceResult());\n    }\n\n    /**\n     * Where are this reference result from? Used to disambiguate if there are multiple providers.\n     * @return Provider name, can be the name of the SOTA algorithm, the authors, or any other id that clearly identifies the source.\n     */\n    @Override\n    public String getProviderName() {\n        return \"RaulEtAl2019\";\n    }\n}\n</code></pre> <p>Tip</p> <p>If there are multiple reference results for the given instance (for example, when there are multiple previous works using different approaches), we can just extend several times the class <code>ReferenceResultProvider</code> as long as the <code>getProviderName()</code> method returns an unique value in each implementation.</p>"},{"location":"features/config/","title":"App configuration","text":"<p>Instead of hardcoding different values during app compilation, an easy to use configuration mechanism is provided to easily swap different config parameters, experiments, algorithms, etc., at runtime without recompiling the application. There are multiple ways to pass configuration parameters. For a list of generic available parameters, see the default application.yml provided below.</p>"},{"location":"features/config/#how-to-provide-or-change-configuration-at-runtime","title":"How to provide or change configuration at runtime","text":"<p>There are multiple ways to pass config values or override existing ones if already specified. From more priority to less, the following are available:</p>"},{"location":"features/config/#using-the-command-line","title":"Using the command line","text":"<p><pre><code>java -jar myproject.jar --seed=1235 --instances.path.default=/results\n</code></pre> or using Java properties</p> <pre><code>java -Dseed=1235 -Dinstances.path.default=/results -jar myproject.jar\n</code></pre> <p>Remember: command line config properties always take precedence over any configuration file. If any property is already specified for example in the application.yml, the corresponding value is overriden.</p>"},{"location":"features/config/#using-environment-variables","title":"Using environment variables","text":"<p><pre><code>export INSTANCES_PATH_DEFAULT=\"/results\"\njava -jar myproject.jar\n</code></pre> Note that the equivalent environment variable for a property is calculated as: <code>-</code> are removed, <code>.</code> replaced with <code>_</code>, and the string is uppercased. Environment variables can useful for configuring a given environment for all experiments. Example: if I have a powerful server with 96 real cores (no hyper-threading) I can export the property <code>SOLVER_NWORKERS</code>, and <code>SOLVER_PARALLELEXEUCUTOR</code>, such as: <pre><code>export SOLVER_PARALLELEXEUCUTOR=true\nexport SOLVER_NWORKERS=96\n</code></pre> This way, any experiment launched in this machine will automatically use the parallel executor with 96 cores. This can be automated using <code>.bashrc</code> if using Bash, or <code>.zshrc</code> if using zsh.</p>"},{"location":"features/config/#using-a-configuration-file","title":"Using a configuration file","text":"<p>Place an <code>application.yml</code> on the same folder as the jar. Any property or configuration parameter in this <code>application.yml</code> overrides the corresponding value of the packaged <code>application.yml</code> inside the jar.</p>"},{"location":"features/config/#extending-the-configuration-or-adding-custom-values","title":"Extending the configuration or adding custom values","text":"<p>You may add and use any custom config property inside your implementation. The value for the custom config parameter can be provided with any of the methods explained above. In order to retrieve the config value for any given key at runtime, use the static methods inside the <code>ConfigService</code> class.</p>"},{"location":"features/config/#advanced","title":"Advanced","text":"<p>The app configuration system is inherited from Spring Boot. Everything that can be done as specified in the Spring Boot docs can be done in Mork. See https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.external-config for a full reference.</p>"},{"location":"features/config/#reference-configuration","title":"Reference configuration","text":"<p>The following is a reference configuration as can be found in the generated project. All properties should be properly documented, open an issue or a PR if something is not clear to modify the default configuration file.</p> <pre><code># Defines any custom property or configuration for the current problem.\n# The config values can be retrieved at runtime, for example inside the experiment\n# See https://mork-optimization.readthedocs.io/en/latest/features/config/ for more details\ncustom:\n  my-property: 'myvalue'\n\ninstances:\n\n  # Loads all instances in RAM before starting each experiment.\n  # Can be disabled for example in problems where instances are huge in order to save some RAM.\n  # Warning: Disabling it reverts instance solve order to instance name (lexicographically)\n  preload: true\n\n  path:\n    # Default instance path for all experiments, can be overridden.\n    default: 'instances'\n\n    # Override default instance path only for the experiment declared in file PreliminarExperiment.java\n    # If an experiment does not have a specific path the default will be used. Example:\n    # PreliminarExperiment: './instances/preliminar'\n\n\nsolver:\n  # Global random seed to ensure reproducibility\n  seed: 1234\n\n  # Random generator provider, see RandomType enum for a full list of available implementations\n  random-type: default\n\n  # Which experiments should be executed? .* --&gt; All.\n  # Experiment names default to the class name in which they are declared unless overridden.\n  # Tip, you may use a Regex, example: Preeliminar.*\n  experiments: '.*'\n\n  # How many times should each experiment be repeated. Recommended a minimum of 30\n  repetitions: 100\n\n  # Use parallel executor DISABLE IF THE ALGORITHM IS ALREADY PARALLELIZED\n  # Valid Values: true, false\n  parallelExecutor: false\n\n  # Number of workers to use if parallelExecutor is enabled\n  # any number between 1 and MAX_INT, or -1 to automatically decide at runtime (available threads / 2)\n  nWorkers: -1\n\n  # Execute benchmark before starting solver? False to skip benchmark.\n  benchmark: true\n\n  # Autoconfig properties\n  ## Tree depth when using automatic configuration\n  tree-depth: 4\n  ## For each solution generated by any algorithm, ignore this millis in the area calculation.\n  ## WARNING: Any algorithm that does not report an o.f value before this limit is reached is considered invalid\n  ignore-initial-millis: 10000\n  ## Area will be measured in interval [ignoreInitialMillis, ignoreInitialMillis+intervalDurationMillis]\n  interval-duration-millis: 50000\n  # End autoconfig properties\n\n  # Enable or disable metrics tracking. Force enabled if using autoconfig.\n  metrics: false\n\n# Enable irace integration? Check IRACE Wiki section before enabling\nirace:\n  enabled: false\n\n  # False: (EXPERIMENTAL) use GraalVM implementation, does not need R installed locally\n  # True: (RECOMMENDED) Use shell to execute R scripts, R / Rscript need to be locally installed and in path\n  shell: true\n\n  # Maximum number of algorithm executions\n  maxExperiments: 10000\n\n# Event system integrations/configuration\nevent:\n  # Stop webserver after all work is done?\n  # If true, app will stop after all experiments finish executing, and front end will stop loading. (DEFAULT)\n  # If false, webserver will keep executing, and front will be available until manually stopped by the user.\n  webserver:\n    stopOnExecutionEnd: true\n\n  # Enable message notifications to any given user on experiment end. See\n  telegram:\n    # If false bot is completely disabled\n    enabled: false\n    # Token returned by @BotFather\n    token: ''\n    # Chat where we will send notifications\n    chatId: ''\n\n# Experiment execution DOES NOT (usually) END if an uncontrolled exception is propagated\n# The error is logged, and we try to keep solving\nerrors:\n  # Write exceptions and errors with their context to disk?\n  errorsToFile: true\n\n  # Path where all errors or exceptions encountered during experiment execution will be exported\n  folder: 'errors'\n\n# Set default server port (change if there is multiple Mork instances running)\nserver:\n  port : 8080\n</code></pre>"},{"location":"features/docker/","title":"Docker containers","text":"<p>Docker containers allow anyone to easily reproduce our experiments without any prior knowledge of how our apps works. The container contains all the instances, code, and libraries necessary to easily execute the experiments with a single command.</p>"},{"location":"features/docker/#before-starting","title":"Before starting","text":"<ol> <li>Install Docker: installation instructions are available at https://docs.docker.com/engine/install/.</li> <li>Verify that Docker is working: execute <code>docker run hello-world</code> and check the output.</li> <li>Before publishing any container, you need to create an account in a Docker Registry. If you do not know what a Docker Registry is, create an account in Docker Hub Registry.</li> </ol>"},{"location":"features/docker/#building-and-publishing-your-container","title":"Building and publishing your container","text":"<p>Inside the <code>docker</code> folder, there are several scripts to help with the container lifecycle. We will use them, and modify them if necessary, in order to build, run and publish our container.</p>"},{"location":"features/docker/#building-the-container","title":"Building the container","text":"<p>Execute <code>docker/build.sh username/projectname</code> to build and tag a Docker container with your name and the project name. Both the <code>projectname</code> and the <code>username</code> should be in lowercase.</p> <p>The build process consists of two steps: first, a fat jar is created using <code>maven</code>, and then a container is built using the steps in <code>docker/Dockerfile</code>. The container build steps can be changed to include additional files, dependencies, directories or custom Java VM parameters.</p>"},{"location":"features/docker/#testing-the-container","title":"Testing the container","text":"<p>Once the container is built, and before publishing it, you should test that it correctly works and generates the expected results. Use <code>docker/run.sh username/projectname</code> to run the container and verify that the results inside the <code>results</code> folder are indeed correct.</p>"},{"location":"features/docker/#publishing-your-container","title":"Publishing your container","text":"<p>Publishing your container is extremely simple, execute <code>docker/publish.sh username/projectname</code> and follow the steps. The first time, the script will ask for the Docker Hub account credentials.</p> <p>For a more detailed step by step guide check the official Docker documentation https://docs.docker.com/docker-hub/repos/#pushing-a-docker-container-image-to-docker-hub.</p>"},{"location":"features/docker/#common-questions","title":"Common questions","text":""},{"location":"features/docker/#how-can-people-reproduce-my-experiments","title":"How can people reproduce my experiments?","text":"<p>Once the container is published, anyone can run it using the following command: <pre><code>docker run -t username/projectname\n</code></pre> The only requisite is that they must have Docker installed.</p>"},{"location":"features/docker/#can-i-change-the-configuration-after-publishing-the-container","title":"Can I change the configuration after publishing the container?","text":"<p>Yes, you may provide a different application.yml or custom properties. For a more detailed explanation on how or why the following works, see the docs config page.</p>"},{"location":"features/docker/#using-custom-properties","title":"Using custom properties","text":"<p>Configuration values can be changed via environment variables. For example, changing the solver random seed is as easy as:</p> <pre><code>docker run -e \"SOLVER_SEED=1234\" -t username/projectname\n</code></pre>"},{"location":"features/docker/#using-a-different-applicationyml","title":"Using a different application.yml","text":"<p>It some cases, it may be more confortable to provide a configuration file instead of manually configuring properties. <pre><code>docker run -v \"$(pwd)\"/application.yml:/application.yml -t username/projectname\n</code></pre></p> <p>Remember that any property defined in the new <code>application.yml</code> overrides the corresponding property in the embedded <code>application.yml</code>. If a property is not defined, the embedded value is used.</p>"},{"location":"features/docker/#can-the-container-solve-a-different-set-of-instances","title":"Can the container solve a different set of instances?","text":"<p>Absolutely, you can mount a directory inside the container containing the new set of instances to solve. <pre><code>docker run -v \"$(pwd)\"/newInstances:/newInstances -e \"INSTANCES_PATH_DEFAULT=newInstances\" -t username/projectname\n</code></pre></p>"},{"location":"features/events/","title":"Event system","text":""},{"location":"features/events/#what","title":"What","text":"<p>Events are actions or occurrences in any part of the application, that may or may not be handled by listeners. Events are propagated to event listeners asynchronously when certain actions happen (an instance is loaded, a solution is generated, an experiment ends, etc.)</p>"},{"location":"features/events/#why","title":"Why","text":"<p>Events allow users to easily extend the framework functionality without directly modifying it. Any application component can listen to events and react to them, even triggering events in response. Although not being able to immediately execute a method when something happens may appear a disadvantage, the asynchronous nature of events allows us implement complex behaviour  behind the scene, such as a concurrent or distributed experiment executor, while providing a very simple interface.</p>"},{"location":"features/events/#event-guarantees","title":"Event guarantees","text":"<ul> <li>Events are inmutable</li> <li>Events cannot be canceled or deleted once triggered</li> <li>All Mork events (in general, any event triggered by the framework) are guaranteed to be dispatched  in the correct order, even if the execution order (such us when using a concurrent executor) is not defined.</li> </ul>"},{"location":"features/events/#event-lifecycle","title":"Event lifecycle","text":"<p>Event lifecycle or dispatch order. You may safely assume that the solver engine behaves like a state machine transitioning using the events defined in the diagram.</p> <pre><code>graph TD;\n    ExecS[ExecutionStartedEvent];\n    ExpS[ExperimentStartedEvent];\n    InsS[InstanceProcessingStarted];\n    AlgS[AlgorithmProcessingStarted];\n    SolG[SolutionGeneratedEvent];\n    AlgE[AlgorithmProcessingEnded];\n    InsE[InstanceProcessingEnded];\n    ExpE[ExperimentEndedEvent]\n    ExecE[ExecutionEndedEvent];\n    ExecS--&gt;ExpS;\n    ExpS--&gt;InsS;\n    InsS--&gt;AlgS;\n    AlgS--&gt;SolG\n    SolG--&gt;AlgE;\n    AlgE--&gt;InsE;\n    InsE--&gt;ExpE;\n    ExpE--&gt;ExecE;\n\n    SolG--&gt;|1 to N| SolG;\n    AlgE--&gt;AlgS;\n    InsE--&gt;InsS;\n    ExpE--&gt;ExpS;\n</code></pre>"},{"location":"features/events/#event-types-list","title":"Event types list","text":"<p>Most event names are self-explanatory, in case not:</p> Event name Explanation <code>ExecutionStartedEvent</code> Fired once when solver is ready to start generating solutions <code>ExperimentStartedEvent</code> Fired when starting each experiment <code>InstanceProcessingStartedEvent</code> An instance has been loaded and is going to be solved by different algorithms <code>AlgorithmProcessingStartdEvent</code> A pair (instance, algorithm) is scheduled for execution <code>SolutionGeneratedEvent</code> A solution has been generated for the tuple (Instance, AlgorithmConfig, Iteration) <code>AlgorithmProcessingEndedEvent</code> A pair (instance, algorithm) has finished executing <code>InstanceProcessingEndedEvent</code> An instance has been solved with all algorithm configurations and is no longer needed <code>ExperimentEndedEvent</code> Experiment finalized, if there are no more experiments queued end <code>ExecutionEndedEvent</code> All experiments done, fired before solver shutdowns"},{"location":"features/events/#implementing-an-event-listener","title":"Implementing an event listener","text":""},{"location":"features/events/#backend","title":"Backend","text":"<p>Extend <code>AbstractEventListener</code> and create methods annotated by <code>@MorkEventListener.</code> For example, the telegram bot is implemented using a listener as follows:</p> <pre><code>public class TelegramEventListener extends AbstractEventListener {\n\n    private final TelegramService telegramService;\n    private volatile boolean errorNotified = false;\n\n    public TelegramEventListener(TelegramService telegramService) {\n        this.telegramService = telegramService;\n    }\n\n    // Notify user when experiment ends\n    @MorkEventListener\n    public void onExperimentEnd(ExperimentEndedEvent event) {\n        if (!telegramService.ready()) return;\n        telegramService.sendMessage(String.format(\"Experiment %s ended. Execution time: %s seconds\", event.getExperimentName(), event.getExecutionTime() / 1_000_000_000));\n    }\n\n    // Notify user of the first error\n    @MorkEventListener\n    public void onError(ErrorEvent event) {\n        if (!telegramService.ready()) return;\n        // Only notify first error to prevent spamming\n        if (!errorNotified) {\n            errorNotified = true;\n            var t = event.getThrowable();\n            telegramService.sendMessage(String.format(\"Execution Error: %s. Further errors will NOT be notified.\", t));\n        }\n    }\n\n    // Stop Telegram bot when execution ends\n    @MorkEventListener\n    public void onExecutionEnd(ExecutionEndedEvent event) {\n        telegramService.stop();\n    }\n}\n</code></pre> <p>If you want to listen to all framework events, use the superclass <code>MorkEvent</code>.</p>"},{"location":"features/events/#frontend","title":"Frontend","text":"<p>Implement the methods <code>onEventName()</code>. See <code>app.js</code> file in template project for example implementations.</p> <p>If you want to listen to all framework events use the method <code>onAnyEvent()</code>.</p>"},{"location":"features/events/#using-custom-events","title":"Using custom events","text":"<p>Triggering custom events is extremely easy, for example in custom algorithms such as genetic algorithms.</p> <p>Just extend <code>MorkEvent</code> class, fill with data from any part of your code, and propagate to the framework using <code>EventPublisher.getInstance().publishEvent(event)</code>. Remember that all events are processed asynchronously, and they MUST be immutable (i.e do not implement any setter).</p>"},{"location":"features/instance-manager/","title":"Instance manager","text":"<p>Mork comes with a built-in instance manager, which manages the whole instance load-unload lifecycle,  and provides a way to classify instances based on their properties. </p>"},{"location":"features/instance-manager/#instance-manager-modes","title":"Instance manager modes","text":"<p>The instance manager is configured by using the properties with the prefix <code>instance.*</code>. For example, the default instance path is configured using the property <code>instance.path.default</code>. The <code>default</code> keyword can be replaced with the experiment name,  overriding the instance path for each user defined experiment if necessary. </p> <p>The value of the <code>instance.path</code> property can be interpreted in multiple ways, depending on the path type.</p>"},{"location":"features/instance-manager/#path-is-a-normal-file","title":"Path is a \"normal\" file","text":"<p>In the simplest case, the path represents a single file. In this case, the instance manager will ask the user implemented <code>InstanceImporter</code> to load the instance from the file, and run the experiment using only this file.</p>"},{"location":"features/instance-manager/#path-is-a-compressed-file","title":"Path is a compressed file","text":"<p>If the path is a compressed file, the instance manager will decompress each file in memory, and get an input stream to avoid disk I/O. This is useful when the instances are compressed to save disk space, as  decompression only happens in memory when required. From the user point of view, this is done transparently, and the same method of the <code>InstanceImporter</code> is called, regardless of the file being compressed or not. If the compressed file contains multiple files or directories, they are recursively enumerated.</p>"},{"location":"features/instance-manager/#path-is-a-directory","title":"Path is a directory","text":"<p>If the path is a directory, the instance manager will enumerate all files in the directory, and load each file as an instance. If the directory contains directories, they will be recursively enumerated. If there are compressed files inside the directory, they will be processed as explained in the previous section.</p>"},{"location":"features/instance-manager/#path-is-an-index-file","title":"Path is an index file","text":"<p>Index files are a way to group instances together, without splitting them in different folders.  They are specially useful when instances are extremely big, to avoid data duplication. </p> <p>For example, if we have a folder called \"instances\", which contains all the known instances in the literature for the problem we are currently solving,  we may want to execute only a subset of this instance set, for example when running preliminary experiments. An easy way to do this is to create a new instance folder, called <code>preliminary-instances</code>, and copy the instances that we want to run there. However, this approach has the downside of duplicating the data, which can be a problem if the instances are huge. As an alternative, we can create a file inside the <code>instances</code> folder, called <code>preliminary.index</code>, which contains the names of the instances that we want to run. The instance manager will read this file, and load only the instances that are listed there, ignoring the rest.</p> <p>Info</p> <p>Note that a index files are identified by the <code>.index</code> extension, and are ignored when enumerating instances if they are not explicitly configured as the <code>instance.path</code> properties. </p>"},{"location":"features/instance-manager/#instance-loading","title":"Instance loading","text":"<p>In order to load instances, users must extend the <code>InstanceImporter</code> class. By default, the following template is generated by the Mork generator:</p> <pre><code>public class ExampleInstanceImporter extends InstanceImporter&lt;__RNAME__Instance&gt; {\n\n    @Override\n    public ExampleInstance importInstance(BufferedReader reader, String suggestedName) throws IOException {\n        // Create and return instance object from file data\n        // TODO parse all data from the given reader however I want\n\n        // TIP: You may use a Scanner if you prefer it to a Buffered Reader:\n        // Scanner sc = new Scanner(reader);\n\n        // Call instance constructor when we have parsed all the data, passing data as we see fit\n        var instance = new ExampleInstance(suggestedName);\n\n        // IMPORTANT! Remember that instance data must be immutable from this point\n        return instance;\n    }\n}\n</code></pre> <p>One important thing to always take into account is that instances must be immutable after they have been loaded. This means that under no circumstance should the instance data be modified after the <code>importInstance</code> method has finished. The reason for this is that immutable data can be safely and efficiently shared between threads,  which is a key feature for Mork's parallel execution. </p> <p>Tip</p> <p>Note that if you want to precalculate any kind of data, it is perfectly valid to do it while loading the instance, before returning.</p>"},{"location":"features/instance-manager/#advanced-loading-methods","title":"Advanced loading methods","text":"<p>In some cases, the same logical instance is split in multiple files, or maybe instance data follows a customized binary and you have an existing method that receives a File objects and initializes the instance. In these advanced use cases, where more control over the loading process is needed, the second overload of the <code>importInstance</code> method can be used instead. For example: <pre><code>public class ExampleInstanceImporter extends InstanceImporter&lt;ExampleInstance&gt; {\n    @Override\n    public ExampleInstance importInstance(BufferedReader reader, String suggestedName) throws IOException {\n        throw new UnsupportedOperationException(\"Loading from a BufferedReader is not supported\");\n    }\n\n    @Override\n    public ExampleInstance importInstance(String path) {\n        var file = new File(path);\n        // call our custom method to load the instance\n        ExampleInstance instance = customLoadMethod(file);\n        return instance;\n    }\n}\n</code></pre></p>"},{"location":"features/instance-manager/#instance-solve-order","title":"Instance solve order","text":"<p>By default, instances are solved in lexicographic order, which means sorting instances by their filename.  If you want to solve instances in a specific order, for example from smaller to bigger instances, you can  override the <code>compareTo</code> method of the <code>Instance</code> class. For example: <pre><code>    /**\n     *\n     * Sort instances by their node count, from smaller to bigger\n     * @param o the instance to compare to\n     * @return a negative integer, zero, or a positive integer as this instance is less than, equal to, or greater than the specified instance.\n     */\n    @Override\n    public int compareTo(Instance o) {\n        return this.nNodes.compareTo(o.nNodes);\n    }\n</code></pre></p> <p>Tip</p> <p>Instead of manually implementing the compare or comparator methods, which can sometimes be confusing, we recommend using the <code>Comparator.comparing</code> methods or the property comparator directly, as the previous example.</p>"},{"location":"features/instance-manager/#instance-unloading","title":"Instance unloading","text":"<p>By default, instances are validated and cached before the experiment starts running, which means that if they  fit in memory, I/O is reduced to a minimum. If they do not fit into memory,  they are loaded and unloaded as needed, which is suboptimal but works fine without user intervention. </p> <p>This feature is called instance preloading, and while it is is enabled by default,  it can be disabled by setting <code>instances.preload</code> to <code>false</code>. The main advantages of instance preloading are that you make sure all instances can be actually loaded before the experiment starts, so any mistake is detected as early as possible, and that you avoid I/O during the experiment execution. Moreover, preloading is required if a custom solve order is used.</p> <p>However, if the instances are huge, you do not need to solve the instances in any given order, and you are sure that all instances are valid, you can safely disable this feature. </p> <p>Tip</p> <p>As a general rule, do not use automatic parallelization if instances are huge. The reason for this is that multiple threads can be solving different instances, and therefore Mork will be forced to keep multiple instances in memory at the same time, which can produce out-of-memory errors.</p>"},{"location":"features/instance-selection/","title":"Automatic instance selection","text":"<p>Since v0.18, Mork includes an automatic instance selector that can be used to decide which instances  to use for the preliminary experimentation without user intervention.</p>"},{"location":"features/instance-selection/#tldr","title":"TL;DR","text":"<p>Any JAR file built con Mork v0.18 or later, can be invoked as follows: <pre><code>java -jar MyProblem.jar --instance-selector\n</code></pre></p> <p>Selected instances are copied to the output folder,  along some diagrams explaining the decisions taken along the process.</p> <p>Demo</p>"},{"location":"features/instance-selection/#requirements","title":"Requirements","text":"<p>Python3 and pip must be installed and available in PATH.  Required Python dependencies for the instance selector are automatically installed using pip.</p> <p>Moreover, the instance must declare at least one numeric property to use for classification.  The more properties declared, the better. Any redundant information in instance properties will be  automatically removed, see section How it works for more information.</p> <p>Instance properties can be easily declared during instance load or during instance construction using the method <code>MyProblemInstance::setProperty(name,value)</code>. For example, in the DRFLP problem I declared the properties as follows: <pre><code>    @Override\n    public DRFLPInstance importInstance(BufferedReader reader, String filename) {\n        Scanner sc = new Scanner(reader);\n        // Instance parsing code removed for simplicity\n        ...\n\n        var instance = new DRFLPInstance(filename, facilities, weights);\n        double[] avgs = new double[n];\n        for (int i = 0; i &lt; weights.length; i++) {\n            var row = weights[i];\n            avgs[i] = (double) ArrayUtil.sum(row) / n;\n        }\n        instance.setProperty(\"n\", n);\n        instance.setProperty(\"avgWeights\", ArrayUtil.sum(avgs) / n);\n        instance.setProperty(\"minWeights\", ArrayUtil.min(avgs));\n        instance.setProperty(\"maxWeights\", ArrayUtil.max(avgs));\n        return instance;\n    }\n</code></pre></p>"},{"location":"features/instance-selection/#configuration","title":"Configuration","text":"<p>The behaviour of the instance selector can be easily configured, using the following properties:</p> Property Description Default value <code>instances.preliminar-percentage</code> Which proportion of the total set of instances should be selected. Value must be in range (0, 1) 0.15 <code>instances.preliminar-output-path</code> Where should be the preliminary instances be copied, and where to save the generated diagrams output <code>instances.for-selection</code> Path to the whole set of instances Property <code>instances.path.default</code> <p>For example, to use a 20% preliminary set size, and output results to folder preliminar-output, the command would be similar to: <pre><code>java -jar MyProblem.jar --instance-selector --instances.preliminar-percentage=0.2 --instances.preliminar-output-path=preliminar-output\n</code></pre></p>"},{"location":"features/instance-selection/#how-it-works","title":"How it works","text":""},{"location":"features/instance-selection/#loading","title":"Loading","text":"<p>The instance selector will load all instances specified in property <code>instances.for-selection</code>, or if not defined, <code>instances.path.default</code>. If the folder contains folders inside, they will be recursively enumerated. For each instance, all declared properties are calculated, and non-numeric properties are ignored. A CSV file with the raw property data is exported as <code>instance_properties.csv</code>, with a content similar to the following: <pre><code>id,avgWeights,maxWeights,minWeights,n\nA60_01.txt,2.00,3.86,0.46,60.0\nA60_02.txt,1.14,2.7,0.26,60.0\nA60_03.txt,0.96,2.68,0.13,60.0\nA60_04.txt,0.51,1.18,0.0,60.0\nA60_05.txt,0.63,1.41,0.05,60.0\nA70_01.txt,1.09,2.74,0.18,70.0\nA70_02.txt,1.28,2.64,0.12,70.0\nA70_03.txt,1.03,2.2,0.15,70.0\nA70_04.txt,0.67,1.31,0.14,70.0\nA70_05.txt,3.19,6.71,0.47,70.0\nsko56_01.txt,2.72,3.66,1.87,56.0\nsko56_02.txt,2.72,3.66,1.87,56.0\nsko56_03.txt,2.72,3.66,1.87,56.0\nsko56_04.txt,2.72,3.66,1.87,56.0\nsko56_05.txt,2.72,3.66,1.87,56.0\n</code></pre></p>"},{"location":"features/instance-selection/#correlation-and-filtering","title":"Correlation and filtering","text":"<p>The data is then loaded by the Python script <code>instance_selector.py</code>, and the first step is  calculating the correlation between each pair of properties, and exporting it to <code>$output/correlation.pdf</code>. Example: </p>"},{"location":"features/instance-selection/#principal-component-analysis","title":"Principal Component Analysis","text":"<p>Then, characteristics are standardized and the PCA (Principal Component Analysis) method is used to reduce the dimensionality of the characteristics set.  To decide how many components should be used, we select the minimum number of components whose accumulated explained variance ratio is greater than a configured preset, normally 90%, and the <code>$output/pca.pdf</code> is generated  containing a diagram detailing this step. </p>"},{"location":"features/instance-selection/#clustering","title":"Clustering","text":"<p>Once the dimensionality is reduced, the next step is clustering the instances, using the k-means++ algorithm. Because the number of clusters is not known in advance, we use the elbow method to decide a reasonable number of clusters. The elbow method is based on the fact that the distortion score for each clustering try will decrease as we increase the number of clusters, with diminishing returns.  We select the number of clusters where the slope of the curve has a significant change, visually, the elbow of the curve. The diagram <code>$output/kElbow.pdf</code> and <code>$output/pairPlots.pdf</code> are generated. Te first one explains the decisions taken in this step for the current user execution, with a content similar to the following: </p> <p>While the second one can be used to visually validate the quality of the clustering: </p>"},{"location":"features/instance-selection/#instance-ranking","title":"Instance ranking","text":"<p>The last step consists on ranking the instances in each cluster according to their distance to the cluster centroid, and selecting the top instances for each cluster, up to the number of instances requested.  The amount of selected preliminary instances is the multiplication of the ratio defined by the user and the total number of instances detected.</p>"},{"location":"features/irace/","title":"Irace Integration","text":""},{"location":"features/irace/#what-is-irace","title":"What is IRACE?","text":"<p>In short, Irace is a software package that implements a number of automatic configuration procedures, that allows us to easily tune our algorithms when manually testing each possible configuration is not viable.</p> <p>Irace is integrated in Mork, so tuning your algorithms is extremely easy.</p> <p>See the official documentation for more information about Irace. https://cran.r-project.org/web/packages/irace/vignettes/irace-package.pdf</p>"},{"location":"features/irace/#requirements","title":"Requirements","text":"<p>Inside the default <code>application.yml</code> you may see a section similar to this: <pre><code># Enable irace integration? Check IRACE Wiki section before enabling\nirace:\n  enabled: false\n\n  # False: use GraalVM implementation, does not need R installed locally\n  # True: Use shell to execute R scripts, R/Rscript need to be locally installed and in path\n  shell: true\n</code></pre></p> <p>When <code>irace.enabled</code> is true, user defined experiments are ignored, and a special tuning experiment is executed using the user provided scenario.</p> <p>In order to use Irace, you need to either use GraalVM (and set <code>irace.shell</code> to <code>false</code>) or install R/Rscript locally (and set <code>irace.shell</code> to <code>true</code>).</p>"},{"location":"features/irace/#option-a-using-graalvm","title":"Option A: Using GraalVM","text":"<ul> <li>Install and configure the GraalVM, the recommended way is to use sdkman.</li> <li>Follow the instructions in https://www.graalvm.org/reference-manual/r/</li> <li>Set <code>irace.shell</code> to <code>false</code>. <pre><code># Example installation instructions\nsdk install java 21.3.0.r17-grl # Use sdk list java to see latest available GraalVM version\ngu install R\n</code></pre></li> </ul>"},{"location":"features/irace/#option-b-using-native-r","title":"Option B: Using native R","text":"<ul> <li>Install and configure R for your environment: https://cran.r-project.org/bin/</li> <li>Test that R and Rscript are available as commands in your favorite console.</li> <li>Set <code>irace.shell</code> to <code>true</code></li> </ul>"},{"location":"features/irace/#how-to-use-it","title":"How to use it","text":"<p>There are three main things that have to be done in order to use Irace. 1. Configuring dynamic algorithm generation. 2. Defining algorithm parameters to test. 3. Adjusting scenario options.</p> <p>Please read the complete set of steps before proceeding.</p>"},{"location":"features/irace/#configuring-dynamic-algorithm-generation","title":"Configuring dynamic algorithm generation","text":"<p>In a normal experiment, algorithm configurations are defined inside an experiment. When using Irace, algorithms must be dynamically built to match the different configurations Irace wants to test.</p> <ol> <li>Create a new Java class that extends <code>AlgorithmBuilder</code>.</li> <li>Override the method<code>buildFromConfig</code>. Note that this method returns a single <code>Algorithm</code> object, unlike the other experiments where a list of experiments is returned.</li> <li>The <code>buildFromConfig</code> method receives an <code>AlgorithmConfiguration</code> object as an input parameter. This parameter is used to determine the configuration of the algorithm to be tuned. To access the value of each of the parameters that configure the algorithm the method <code>getValue</code> is used. Note that this method returns an Optional if a default value is not provided, given the fact that Irace may supply a given parameter only in certain configurations (Conditional parameters can be defined inside the parameters.txt file, for example only provide an alpha value if a GRASP like constructive is used). <p>Tip: If you are certain a given parameter is always present, use <code>configuration.get(\"parameterName\").orElseThrow()</code>. If for whatever reason the parameter is NOT present, an Exception will be thrown.</p>"},{"location":"features/irace/#defining-algorithm-parameters-to-test","title":"Defining algorithm parameters to test","text":"<p>The parameters of the target algorithm are defined by a parameter file <code>parameters.txt</code> located in <code>src/main/resources/irace/parameters.txt</code>.</p> <p>Each target parameter has an associated type that defines its domain and the way Irace handles them internally.  The four basic types supported by irace are: Real, Integer, Categorical and Ordinal. The parameter file format follows a table like scheme, where each row is defined as:</p> <pre><code>&lt;name&gt; &lt;label&gt; &lt;type&gt; &lt;range&gt; [| &lt;condition&gt;]\n</code></pre> <ul> <li>The <code>name</code> of the parameter as an unquoted alphanumeric string.</li> <li>A <code>label</code> for this parameter. This label will be later used in the <code>getValue</code> method of the <code>IraceConfiguration</code> object. Unless you have a reason not to, it is a good idea to match the name plus the equals sign. (i.e:  if the parameter name is <code>alpha</code>, use <code>alpha=</code> as the label value.</li> <li>The <code>type</code> of the parameter, either integer, real, ordinal or categorical, given as a single letter: \u2018i\u2019, \u2018r\u2019, \u2018o\u2019 or \u2018c\u2019.</li> <li>The <code>range</code> or set of values of the parameter delimited by parentheses. e.g., (0,1) or (a,b,c,d).</li> <li>An optional <code>condition</code> that determines whether the parameter is enabled or disabled, thus making the parameter conditional. If the condition evaluates to false, then no value is assigned to this parameter, and neither the parameter value nor the corresponding label are passed to algorithm. The condition must be a valid R logical expression.</li> </ul>"},{"location":"features/irace/#adjusting-scenario-options","title":"Adjusting scenario options","text":"<p>The scenario allows specifying a text file that contains an initial set of configurations to start the execution of Irace. Particularly, this configuration is defined in <code>scenario.txt</code> file located in <code>src/main/resources/irace/scenario.txt</code> .</p>"},{"location":"features/irace/#more-info","title":"More info","text":"<p>Check full parameter.txt and scenario.txt documentation in the official Irace manual.</p> <p>More information in the guidelines provided in the published article: \"The irace package: Iterated racing for automatic algorithm configuration\", or in the irace package documentation: \"The irace Package: User Guide\".</p> <p>Reminder!:  When the irace option is activated ( <code>irace.enabled = true</code> ), no other user defined experiments will execute.</p>"},{"location":"features/logging/","title":"Logging system","text":""},{"location":"features/logging/#introduction","title":"Introduction","text":"<p>Commonly you may need to print any information to see your algorithm progress or to debug it. Although you may be tempted to use <code>System.out</code>, or <code>System.err</code>, it should be avoided, using a <code>Logger</code> object instead.  Loggers have multiple advantages, among them:</p> <ul> <li>You can configure the level of information to print, so you can print more information when debugging and less when running the algorithm. Forget about commenting and uncommenting <code>System.out.println</code> lines!</li> <li>Performance: <code>Logger</code> objects are optimized to be used in production environments, so they are faster than <code>println</code> statements.</li> <li>You can configure the output format, so you can print the information in a more readable way. For example, by default console output is colored!</li> <li>You can configure the output destination, both by log origin, and by level. For example, you can redirect an experiment log to a file, while keeping general information in the console.</li> </ul> <p>For this purpose, Mork provides a logging system based on SLF4J. Stop using <code>System.out</code> today!</p>"},{"location":"features/logging/#how-to-use-it","title":"How to use it","text":""},{"location":"features/logging/#declaring-a-logger","title":"Declaring a logger","text":"<p>In any file, you can declare a logger as follows:</p> <pre><code>private static final Logger logger = LoggerFactory.getLogger(MyClass.class);\n</code></pre> <p>Where <code>MyClass</code> is the name of the class where you are declaring the logger. This is important, as it will be used to identify the origin of the log message.</p> <p>Warning</p> <p>When importing the Logger and LoggerFactory classes, make sure to use the ones from the <code>org.slf4j</code> package. Specifically, avoid using <code>java.util.logging</code> classes, as their usage convention is completely different.</p>"},{"location":"features/logging/#logging-messages","title":"Logging messages","text":"<p>In any method, you can log messages using the logger object as follows:</p> <pre><code>public int improve(Solution s, List&lt;Improver&lt;Solution, Instance&gt;&gt; improvers) {\n    double scoreBeforeAll = s.getScore();\n    double scoreBefore = scoreBeforeAll;\n    for (var : improvers) {\n        s = improver.improve(s);\n        logger.trace(\"Improver {}: {} --&gt; {}\", improver.getClass().getSimpleName(), scoreBefore, s.getScore());\n        scoreBefore = s.getScore();\n    }\n    logger.debug(\"Total improvement: {}\", scoreBeforeAll - s.getScore());\n}\n</code></pre> <p>Formatting strings is an expensive operation, that should not be done if the given log level is not enabled.  Avoid concatenating concatenating strings, or using <code>String::format</code>. As seen in the previous example,  use a fixed string, with <code>{}</code> as placeholders, and then pass the objects to be formatted as arguments to the logger call.</p> <p>In more complex cases, you may need to invoke some methods to generate some debugging information, and doing everything in the logger call may be unreadable. In this cases, you can guard the expression using <code>Logger::isLevelEnabled</code>, and then calling the expensive methods and the log call only if the level is enabled. Example:</p> <pre><code>if (logger.isDebugEnabled()) {\n    var expensiveResult = someExpensiveMethod();\n    logger.debug(\"The current solution is: {} -&gt; {}\", s, expensiveResult);\n}\n</code></pre>"},{"location":"features/logging/#log-levels","title":"Log levels","text":"<p>In Mork, the log levels are used as follows:</p> <ul> <li>ERROR: Used for anything that keeps us from continuing. For example, missing mandatory components, or invalid configurations.</li> <li>WARN: Used for anything that may cause problems if not managed, or unexpected things that although not strictly invalid, it may not be what the user wants, or missing best practices. For example, using a deprecated method, or a configuration that is known to cause performance issues.</li> <li>INFO: Used for anything that may be interesting for the user to know, but can be safely ignored. For example, the current experiment status, number of iterations remaining, etc.</li> <li>DEBUG: Using to print internal information about each component. For example, algorithm components will track their progress and log it using a DEBUG level. Very useful for debugging purposes.</li> <li>TRACE: Used to print very detailed information about a component. Each operations is logged. For example, each movement applied to the solution in an improvement method. Note that enabling TRACE level may produce a huge amount of information, and may have a big performance impact, so it should be used carefully.</li> </ul>"},{"location":"features/logging/#logging-configuration","title":"Logging configuration","text":"<p>Configuration is managed by the logging framework implementation, in this case Logback. Inside the <code>resources</code> folder, there is a <code>logback.xml</code> file, which contains the default configuration. You can modify it to suit your needs. The most relevant sections of the file are detailed next.</p>"},{"location":"features/logging/#log-levels_1","title":"Log levels","text":"<p>Each package and class can be configured to use a different log level. For example, you may want to print all the information about the experiment progress, but only print warnings or errors in your own classes.  To configure the log level of a package, use the <code>logger</code> tag, specifying a log level for the given package. For example:</p> <pre><code>&lt;logger name=\"es.urjc.etsii.grafo.myProblem\" level=\"DEBUG\"/&gt;\n</code></pre> <p>Would configure the log level of all loggers in the <code>es.urjc.etsii.grafo.myProblem</code> package to <code>DEBUG</code>.  Log levels are inherited by default, but can be overriden. For example, the following configuration:</p> <pre><code>&lt;logger name=\"es.urjc.etsii.grafo.myProblem\" level=\"INFO\"/&gt;\n&lt;logger name=\"es.urjc.etsii.grafo.myProblem.localsearch\" level=\"TRACE\"/&gt;\n</code></pre> <p>Would configure the log level of all classes inside the <code>es.urjc.etsii.grafo.myProblem</code> package to <code>INFO</code>, and all classes inside the <code>es.urjc.etsii.grafo.myProblem.localsearch</code> package to <code>TRACE</code>.</p>"},{"location":"features/logging/#appenders","title":"Appenders","text":"<p>Appenders are the log destinations, where the messages will be sent.  By default, two appenders are configured, a console appender, which prints log messages to the console, and a file appender, which prints them to the configured file. For the full list of available appenders and their configurable parameters, see the reference Logback documentation.</p> <p>Appenders can declare their own filters, to filter the messages that are sent to them. For example, the Console appender is configured to ignore all messages below the <code>DEBUG</code> level, so <code>TRACE</code> messages are not printed to the console. Reference filters documentation.</p> <p>If adding a new appender, remember to add it to the root logger, so it is used. For example, a want to create a custom appender that filters ERROR messages and sends them to a file:</p> <pre><code>&lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n    &lt;file&gt;errors.txt&lt;/file&gt;\n    &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt;\n        &lt;fileNamePattern&gt;errors-%d{yyyy-MM-dd}.%i}.gz&lt;/fileNamePattern&gt;\n        &lt;maxFileSize&gt;${LOGBACK_ROLLINGPOLICY_MAX_FILE_SIZE:-10MB}&lt;/maxFileSize&gt;\n    &lt;/rollingPolicy&gt;\n    &lt;encoder&gt;\n        &lt;pattern&gt;\n            %clr([%d{HH:mm:ss}]){faint} %clr(%-5level) %clr(%-26.26logger{25}){cyan} %clr(:){faint} %m%n\n        &lt;/pattern&gt;\n    &lt;/encoder&gt;\n    &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;\n        &lt;level&gt;ERROR&lt;/level&gt;\n    &lt;/filter&gt;\n&lt;/appender&gt;\n</code></pre> <p>and add it to the root logger</p> <pre><code>&lt;root level=\"info\"&gt;\n    &lt;appender-ref ref=\"STDOUT\"/&gt;\n    &lt;appender-ref ref=\"FILE\"/&gt;\n    &lt;appender-ref ref=\"ERROR2FILE\"/&gt;\n&lt;/root&gt;\n</code></pre>"},{"location":"features/logging/#example-configuration","title":"Example configuration","text":"<p>Tip</p> <p>This configuration is provided as an example, and may diverge from the current recommended configuration.  The latest recommended logging configuration can always be found in the Mork repository</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;configuration&gt;\n    &lt;!-- Each logger level can be independently configured here --&gt;\n    &lt;!-- Set our own log level to INFO by default --&gt;\n    &lt;logger name=\"es.urjc.etsii.grafo\" level=\"INFO\"/&gt;\n\n    &lt;!-- Override info level for the executor package, to print in real time information about the experiment progress --&gt;\n    &lt;logger name=\"es.urjc.etsii.grafo.executors\" level=\"DEBUG\"/&gt;\n\n    &lt;!-- If any algorithm component does not behave as expected, you can set the log level to DEBUG to see what is going on --&gt;\n    &lt;!-- TRACE log level is reserved for generating very detailed information, for example in an improver method it will\n     dump each operation performed for all solutions. --&gt;\n\n    &lt;!--    &lt;logger name=\"es.urjc.etsii.grafo.improve\" level=\"DEBUG\"/&gt;--&gt;\n    &lt;!--    &lt;logger name=\"es.urjc.etsii.grafo.algorithms\" level=\"DEBUG\"/&gt;--&gt;\n\n\n    &lt;!-- Reduce the noise generated by the following packages --&gt;\n    &lt;logger name=\"org.apache.poi.util.XMLHelper\" level=\"ERROR\"/&gt;\n    &lt;logger name=\"org.apache.catalina\" level=\"WARN\"/&gt;\n    &lt;logger name=\"org.springframework\" level=\"WARN\"/&gt;\n\n    &lt;!-- Console appender, to write logs to the console --&gt;\n    &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n        &lt;encoder&gt;\n            &lt;!-- The pattern deletes the current line using ANSI scape sequences, so the progress bar is not printed multiple times --&gt;\n            &lt;pattern&gt;\\\\u001b[2K\\r%clr([%d{HH:mm:ss}]){faint} %clr(%-5level) %clr(%-26.26logger{25}){cyan} %clr(:){faint} %m%n&lt;/pattern&gt;\n        &lt;/encoder&gt;\n        &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt;\n            &lt;!-- We can filter the logs printed to the console, for example to print only INFO\n            and above to the console but keep DEBUG or TRACE to the file. By default filters TRACE logs --&gt;\n            &lt;level&gt;DEBUG&lt;/level&gt;\n        &lt;/filter&gt;\n    &lt;/appender&gt;\n\n    &lt;!-- Write all logs to a file, with a rolling policy to avoid filling the disk.\n    Each time the file size reaches the limit, or the current day changes, it is compressed and a new file is created. --&gt;\n    &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n        &lt;file&gt;log.txt&lt;/file&gt;\n        &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt;\n            &lt;fileNamePattern&gt;log-%d{yyyy-MM-dd}.%i}.gz&lt;/fileNamePattern&gt;\n            &lt;maxFileSize&gt;${LOGBACK_ROLLINGPOLICY_MAX_FILE_SIZE:-10MB}&lt;/maxFileSize&gt;\n        &lt;/rollingPolicy&gt;\n        &lt;encoder&gt;\n            &lt;pattern&gt;\n                %clr([%d{HH:mm:ss}]){faint} %clr(%-5level) %clr(%-26.26logger{25}){cyan} %clr(:){faint} %m%n\n            &lt;/pattern&gt;\n        &lt;/encoder&gt;\n    &lt;/appender&gt;\n\n    &lt;root level=\"info\"&gt;\n        &lt;appender-ref ref=\"STDOUT\" /&gt;\n        &lt;appender-ref ref=\"FILE\"/&gt;\n    &lt;/root&gt;\n    &lt;include resource=\"org/springframework/boot/logging/logback/defaults.xml\" /&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"features/serialization/","title":"Results and serialization","text":"<p>Experiment results and solution data can be exported to multiple formats. By default, Mork provides implementations  to export experiment results to CSV/TSV and XLSX (Microsoft Excel 2007+) and solution data to JSON.  More formats can be added by the user.  If you implement a format that may be useful for other people, consider submitting a Pull Request!</p>"},{"location":"features/serialization/#csv-serialization","title":"CSV serialization","text":"<p>Experiment data can be serialized to CSV like formats, using the separator defined in the configuration, which defaults to ','. For example, by changing the separator to a tab '\\t', the format would be TSV.</p>"},{"location":"features/serialization/#excel-serialization","title":"Excel serialization","text":"<p>Experiment data can be exported to the XLSX format, which allows us to create calculated fields with formulas  and interactive data automatically without intervention. By default, the Excel file contains two sheets,  one with the raw data and another one with an interactive pivot table that allows us to quickly filter and  analyze the results.</p>"},{"location":"features/serialization/#configuring-pivot-table-fields","title":"Configuring pivot table fields","text":"<p>Although the fields in the pivot table can be configured in Excel, in order to save time we can optionally configure them directly inside the application.yml file.</p> <pre><code># [seralizers.xlsx section]\n\n    # Show best (min or max) score in pivot table\n    bestScoreEnabled: true\n\n    # Show average score in pivot table\n    avgScoreEnabled: false\n\n    # Show standard deviation of solution score in pivot table. Uses Excel STD_DEVP function\n    stdScoreEnabled: false\n\n    # Show variance of score in pivot table. Uses Excel VARP function\n    varScoreEnabled: false\n\n    # Show average time in seconds per iteration in pivot table.\n    avgTimeEnabled: false\n\n    # Show total time in seconds for a given (algorithm, instance) in pivot table.\n    totalTimeEnabled: true\n\n    # Show average time to the best solution in seconds in pivot table.\n    avgTTBEnabled: false\n\n    # Show total time to the best solution in seconds in pivot table.\n    totalTTBEnabled: false\n\n    # Show number of times a given algorithm reaches the best known solution.\n    sumBestKnownEnabled: false\n\n    # Show 1 if a given algorithm reaches the best solution for an instance, 0 otherwise.\n    hasBestKnownEnabled: true\n\n    # Show average percentage deviation to best known solution in pivot table.\n    avgDevToBestKnownEnabled: false\n\n    # Show minimum percentage deviation to best known solution in pivot table.\n    minDevToBestKnownEnabled: true\n\n    # Show generated grand total in pivot table\n    rowGrandTotal: false\n    columnGrandTotal: false\n</code></pre>"},{"location":"features/serialization/#adding-custom-data","title":"Adding custom data","text":"<p>You may create charts, new sheets, tables, etc from within your code by extending the <code>ExcelCustomizer</code> class,  using the method <code>customize(XSSFWorkbook excelBook)</code>. The <code>XSSFWorkbook</code> is  the current opened Excel file. Any dependency can be declared in the constructor of your implementation, and it will be automatically be provided at runtime. Example: <pre><code>public class MyExcelCustomizer extends ExcelCustomizer {\n\n    private final AbstractEventStorage&lt;MySolution, MyInstance&gt; events;\n    public MyExcelCustomizer(AbstractEventStorage&lt;MySolution, MyInstance&gt; events) {\n        this.events = events;\n    }\n\n    @Override\n    public void customize(XSSFWorkbook excelBook) {\n        var sheet = excelBook.createSheet(\"MyCustomSheet\");\n\n        var allSolutions = this.events.getEventsByType(SolutionGeneratedEvent.class).toList();\n        for(var event: allSolutions){\n            double score = event.getScore();\n            long execTime = event.getExecutionTime();\n\n            // Do some processing and write it to the excel file!\n            sheet.createRow(); \n            // [...]\n        }\n    }\n}\n</code></pre> See event docs for more information about how the event system works. All events generated during the execution are available using an <code>AbstractEventStorage</code>. It is guaranteed that the customize method will be invoked after the default Excel sheets are generated, so you may always modify the existing data and adapt it to your needs.</p> <p>Mork uses Apache POI 5 to create the XLSX files, see the official Javadoc for more information on how to do common operations such as creating new sheets and setting cell values.</p>"},{"location":"features/serialization/#solution-serialization","title":"Solution serialization","text":"<p>By default, solutions can be exported to file using the JSON format.  See next section if you want to implement a custom export format.</p>"},{"location":"features/serialization/#custom-solution-serializer","title":"Custom Solution Serializer","text":"<p>You may define a custom solution serializer to export solutions to any given format.</p>"},{"location":"features/serialization/#creating-a-configuration-class","title":"Creating a configuration class","text":"<p>The following class will store your serializer configuration. You may add any custom property needed, or you can leave it empty. All properties will be automatically be filled at runtime with the configuration available from the environment,  the application.yml file and the command line parameters. For more information about the configuration system see here.</p> <pre><code>@Configuration\n@ConfigurationProperties(prefix = \"serializers.solution-yourproblem\")\npublic class YourProblemSolutionSerializerConfig extends AbstractSerializerConfig {\n    private boolean enableXFeature = false; // Default value, will be overridden if defined in the application.yml or any other source\n\n    public boolean isEnableXFeature(){\n        return this.enableXFeature;\n    }\n\n    //[...]\n}\n</code></pre>"},{"location":"features/serialization/#mapping-yourproblemsolutionserializerconfig-to-configuration-properties","title":"Mapping YourProblemSolutionSerializerConfig to configuration properties","text":"<p>After defining the configuration class, you may create a new section inside the application.yml. The properties <code>enabled</code>, <code>folder</code> and <code>format</code> are  common in all serializers. Note that the section name must match the prefix specified in <code>ConfigurationProperties</code> so configuration properties are correctly mapped: <pre><code>serializers:\n  solution-yourproblem:\n    # Enable this serializer.\n    enabled: true\n\n    # Path where solutions created by this serializer will be exported\n    folder: 'solutions'\n\n    # Filename format, replacements are applied as follows\n    # yyyy: replaced with current year, ex 2020\n    # MM, dd, HH, mm, ss: replaced by month, day, hour, minute and seconds\n    # any letters [a-zA-Z] can be part of the filename as long as they are between single quotes\n    # Always prepends ExperimentName, InstanceName and algorithm name to prevent name collisions\n    format: \"'.txt'\"\n\n    # Enable my custom feature\n    enableXFeature: true\n\n    # [Other additional config parameters]\n</code></pre></p>"},{"location":"features/serialization/#creating-the-solution-serializer","title":"Creating the Solution Serializer","text":"<p>The last step is implementing the serializer by extending the AbstractSerializer. <pre><code>public class YourProblemSolutionSerializerConfig extends SolutionSerializer&lt;YourSolutionType, YourInstanceType&gt; {\n\n    /**\n     * Create a new solution serializer with the given config\n     * @param config\n     */\n    public YourProblemSolutionSeralizer(YourProblemSolutionSerializerConfig config) {\n        super(config);\n    }\n\n    @Override\n    public void export(BufferedWriter writer, WorkUnitResult&lt;YourSolutionType, YourInstanceType&gt; result) throws IOException {\n        var data = solution.getSolutionData();\n        StringBuilder sb = new StringBuilder();\n        for(var row: data){\n            for(var f: row){\n                sb.append(f.facility.id);\n                sb.append(\" \");\n            }\n            sb.append('\\n');\n        }\n        writer.write(sb.toString());\n    }\n}\n</code></pre></p> <p>Note: If the method <code>export(BufferedWriter writer, WorkUnitResult&lt;YourSolutionType, YourInstanceType&gt; result)</code> does not provide enough flexibility,  for example if you want to export the solution as an image, you may leave it empty and override  <code>export(File f, WorkUnitResult&lt;YourSolutionType, YourInstanceType&gt; result)</code> instead.</p>"},{"location":"features/serialization/#metrics","title":"Metrics","text":"<p>Mork is able to gather different metrics along the execution of an algorithm.</p> <p>A predefined metric in all Mork available algorithms is <code>BestObjective</code>, which records the evolution of the  objective function on each run. This way, once an algorithm has finished and produced a solution, it is possible to analyze how the objective function has changed during the execution of any given algorithm.  The default JSON serializer saves the metrics along the exported solution if enabled. When using a custom serializer, you control which metrics are saved if any. All metrics data can be accessed from the export method inside your serializer class, using the provided <code>WorkUnitResult</code> as an argument.</p> <p>Remember that metrics may not be enabled by default, the corresponding configuration parameter can be found in the application.yml file: <pre><code>solver:\n\n  #[...]\n\n  # Enable or disable metrics tracking. Force enabled if using autoconfig.\n  metrics: true\n\n  #[...]\n</code></pre></p> <p>If using the default JSON serializer, once the execution has finished, the JSON file containing the solution description will also include values in the metrics section. For each defined metric, it will show pairs of (time, value). All time values are in nanoseconds, and represent the ellapsed time since the experiment started in nanoseconds. The default metric is <code>BestObjective</code>, which watches the objective function value of the best solution. An example of this report follows:</p> <pre><code>\"executionTime\" : 9670583917,\n  \"timeToTarget\" : 9572068250,\n  \"metrics\" : {\n    \"metrics\" : {\n      \"BestObjective\" : {\n        \"values\" : [ {\n          \"instant\" : 180894167,\n          \"value\" : 44704.0\n        }, {\n          \"instant\" : 4650119875,\n          \"value\" : 447.0\n        },  {\n          \"instant\" : 8874177375,\n          \"value\" : 280.0\n        }, {\n          \"instant\" : 9006580125,\n          \"value\" : 277.0\n        }, {\n          \"instant\" : 9572100250,\n          \"value\" : 251.0\n        } ],\n        \"name\" : \"BestObjective\"\n      }\n    },\n    \"referenceNanoTime\" : 821070987037541\n  }\n</code></pre> <p>All algorithms implemented in Mork register the changes to the objective function. If you create new algorithm components, and want to add new datapoints to the BestObjective metric, or in general, to any metric, an statement similar to the following can be included where appropiate, for example each time the best solution is updated: <pre><code>Metrics.add(BestObjective.class, solution.getScore());\n</code></pre> where <code>solution</code> is the best solution managed by the algorithm.</p>"},{"location":"features/telegram/","title":"Telegram Integration","text":""},{"location":"features/telegram/#requirements","title":"Requirements","text":"<p>First of all you need to register a Telegram bot using botfather. Follow the link instructions and return here once you have a bot token: https://core.telegram.org/bots#6-botfather</p> <p>Configure the following section inside your application.yml config file: <pre><code># Event system integrations/configuration\nevent:\n  # Enable message notifications to any given user on experiment end.\n  # See https://github.com/rmartinsanta/mork/wiki/Telegram-integration for more details\n  telegram:\n    # If false bot is completely disabled\n    enabled: false\n    # Token returned by @BotFather\n    token: ''\n    # Chat where we will send notifications\n    chatId: ''\n</code></pre></p> <p>A Telegram bot CANNOT send a message to an user without a valid chatID and without having recived at least ONE message from the given user. To fulfill both requirements at once, send a message to the bot you registered using botfather while the app is running and it will give you back the chatId.</p>"},{"location":"features/validations/","title":"Validation and testing","text":""},{"location":"quickstart/bestpractices/","title":"Common mistakes to avoid","text":"<p>In this page a list of common mistakes to avoid and best practices are enumerated. While some of this are forced by the framework, note that they are meta heuristics development best practices nonetheless.</p>"},{"location":"quickstart/bestpractices/#customized-random-generator","title":"Customized random generator","text":"<p>The random generators follow the seed specified in the application.yml configuration file. As long as the seed is constant the algorithms should always generate the same results.</p> <p>Every time a <code>Random</code> object is required request it with the <code>RandomManager.getRandom()</code> method. Do NOT create your own Random instances manually, and do not use Java API methods that do not allow you to provide a random. Examples:</p> <ul> <li> <p>Do not use <code>Math.random()</code>. Use RandomManager.getRandom() to get a generator and then call <code>nextDouble()</code> instead. <code>Math.random()</code> uses a custom random internally that cannot be controlled. By default, this method is blocked (config property <code>advanced.block.math-random</code>, and trying to invoke it throws an Exception.</p> </li> <li> <p>Do not use <code>Collections.shuffle(Collection&lt;E&gt;)</code>. Use <code>CollectionUtil.shuffle()</code> from mork package instead (which is actually faster!).</p> </li> </ul>"},{"location":"quickstart/bestpractices/#instances","title":"Instances","text":"<p>Instances must be inmmutable after exiting the constructor method. Under no circumstances should an instance change while solving. Remember than you may always extend an <code>InstanceImporter</code> and customize every aspect of the <code>Instance</code> creation while or just after the Instance has been loaded.</p>"},{"location":"quickstart/bestpractices/#solution","title":"Solution","text":"<p>Solutions are always owned by a thread/executor, and only one. This means that you should not implement concurrency controls inside the solution class, specially in the data structures. They will negatively affect computation times without providing any benefits.</p>"},{"location":"quickstart/bestpractices/#algorithms-components","title":"Algorithms &amp; Components","text":"<p>Algorithms and their components must be stateless. This applies to algorithms, constructive methods, local searches, neighborhoods, etc. You should not store any mutable information inside this classes, always use the solution and only the solution class to store mutable data.</p>"},{"location":"quickstart/migrating/","title":"Upgrading from old versions","text":"<p>In this page, you will find instructions and tips for upgrading from older versions of Mork to the latest version.  Note that instructions are provided for upgrading from one mayor version (por example, v0.19), to the next one (v0.20), and so on. If you want to upgrade from a version that is not the immediate previous one, you will need to follow the instructions for each intermediate version.</p>"},{"location":"quickstart/migrating/#upgrading-from-v019-to-v020","title":"Upgrading from v0.19 to v0.20","text":""},{"location":"quickstart/migrating/#objectives-refactor","title":"Objectives refactor","text":"<p>Before, we declared if we were maximizing or minimizing using a parameter when starting Mork, for example: <pre><code>public static void main(String[] args) {\n    Mork.start(args, FMode.MINIMIZE);\n}\n</code></pre> Or using the <code>FMode.MAXIMIZE</code> constant. <pre><code>public static void main(String[] args) {\n    Mork.start(args, FMode.MAXIMIZE);\n}\n</code></pre> Now, we can declare our problem objectives using the static methods in the <code>Objective</code> class, for example: <pre><code>public static void main(String[] args) {\n    Mork.start(args,\n            Objective.ofMinimizing(\"Distance\", TSPSolution::getDistance, TSPMove::getDistanceDelta)\n    );\n}\n</code></pre></p> <p>This way, methods <code>getValue()</code>, <code>recalculateScore()</code>, <code>getScore()</code>, etc. are no longer mandatory, and you do not need to override them. You can still use them if you want, or rename them to whatever name is representative to your problem. In the case of multi objective optimization, objectives can be easily declared as follows: <pre><code>public static void main(String[] args) {\n    Mork.start(args,\n            Objective.ofMinimizing(\"Distance\", TSPSolution::getDistance, TSPMove::getDistanceDelta),\n            Objective.ofMaximizing(\"Profit\", TSPSolution::getProfit, TSPMove::getProfitDelta)\n    );\n}\n</code></pre></p> <p>Note that you can also use lambda expressions instead of method references, for example: <pre><code>public static void main(String[] args) {\n    Mork.start(args,\n            Objective.ofMinimizing(\"Distance\", solution -&gt; solution.getMetrics().distance, move -&gt; move.calculateXYZ() * 4)\n    );\n}\n</code></pre></p>"},{"location":"quickstart/starting/","title":"Getting started","text":"<p>In this page, we will learn how to create an empty Mork project</p>"},{"location":"quickstart/starting/#requirements","title":"Requirements","text":"<p>Before creating a project, you will need to have installed a recent Java SDK and an IDE. We recommend using the latest LTS Java version (Java 17, as of 2022), and IntelliJ as IDE,  either the community or professional edition.</p> <p>Tip</p> <p>Checkout SdkMan for an easy way to install and manage multiple Java SDKs.</p>"},{"location":"quickstart/starting/#creating-a-project","title":"Creating a project","text":"<p>In order to facilitate project creation, we have created a small tool which automatically initializes an empty project. Creating a project this way is extremely easy, visit the tool page, choose a project name,  optionally select the Mork version you want to use (defaults to the latest stable version) and click on Generate Project The tool will generate a ZIP file, that can be extracted anywhere and imported in your favourite IDE.</p> <p></p>"},{"location":"quickstart/starting/#start-developing","title":"Start developing","text":"<p>After opening the project in IntelliJ, you will see something similar to the following .</p> <p>Note</p> <p>Although we recommend using IntelliJ, the project is based Maven, which means it will work on any IDE,  or even without one for the vim fanatics.</p> <p>The easiest way to start the project is by copying the instance data and following the TODO list on the IntelliJ tab.  The TODO list starting with <code>es.urjc...</code> provides a list with the minimum required functionality that must be implemented in order to have a minimal working application. </p> <p></p> <p>Double-clicking any item will take you to the relevant part code. After filling in the blanks,  remember to delete the no longer relevant comments.</p> <p></p> <p>Don't know how to continue? Need inspiration? Take a look at the Examples section, where you will find detailed explanations and step-by-step guides for different optimization problems.  For example The Travelling Salesman Problem.</p>"},{"location":"quickstart/tips/","title":"Tips &amp; Tricks","text":""},{"location":"quickstart/tips/#managing-java-installations","title":"Managing Java installations","text":"<p>Manually installation, updating, and removing old Java versions can get cumbersome. Managing Java versions,  or more in general, Software Development Kits, can be simplified using a tool like SdkMan.</p> <p>For example, listing available Java SDKs is as simple as: <pre><code>sdk list java\n================================================================================\nAvailable Java Versions for Linux 64bit\n================================================================================\n Vendor        | Use | Version      | Dist    | Status     | Identifier\n--------------------------------------------------------------------------------\n Corretto      |     | 19.0.1       | amzn    |            | 19.0.1-amzn\n               |     | 17.0.5       | amzn    |            | 17.0.5-amzn\n               |     | 11.0.17      | amzn    |            | 11.0.17-amzn\n               |     | 8.0.352      | amzn    |            | 8.0.352-amzn\n Dragonwell    |     | 17.0.5       | albba   |            | 17.0.5-albba\n               |     | 17.0.4       | albba   |            | 17.0.4-albba\n               |     | 11.0.17      | albba   |            | 11.0.17-albba\n               |     | 11.0.16      | albba   |            | 11.0.16-albba\n Gluon         |     | 22.1.0.1.r17 | gln     |            | 22.1.0.1.r17-gln\n               |     | 22.1.0.1.r11 | gln     |            | 22.1.0.1.r11-gln\n GraalVM       |     | 22.3.r19     | grl     |            | 22.3.r19-grl\n               |     | 22.3.r17     | grl     |            | 22.3.r17-grl\n               |     | 22.3.r11     | grl     |            | 22.3.r11-grl\n[...]\n</code></pre></p> <p>And installing it: <pre><code>sdk install java 19.0.1-tem\n\nDownloading: java 19.0.1-tem\n\nIn progress...\n\n################################################################################################################################################################################################################################# 100.0%\n\nRepackaging Java 19.0.1-tem...\n\nDone repackaging...\n\nInstalling: java 19.0.1-tem\nDone installing!\n\nDo you want java 19.0.1-tem to be set as default? (Y/n): n\n</code></pre></p> <p>Note</p> <p>Setting a Java SDK as default during installation with SDKMan may only affect new shells,  so you may need to close and open a new one. Moreover, you may need to manually choose in IntelliJ for each project which Java version should be used.</p> <p>For a more detailed explanation, and full usage details see the official SdkMan documentation. </p>"},{"location":"quickstart/troubleshooting/","title":"Common problems","text":"<p>Explanation of different problems, errors and exceptions that may be found while using the framework.</p>"},{"location":"quickstart/troubleshooting/#illegalstateexception-no-language","title":"IllegalStateException: No language ...","text":"<p>An exception such as: <pre><code>Exception in thread \"Thread-2\" java.lang.IllegalStateException: No language and polyglot implementation was found on the classpath. Make sure the truffle-api.jar is on the classpath.\n    at org.graalvm.polyglot.Engine$PolyglotInvalid.noPolyglotImplementationFound(Engine.java:1001)\n    at org.graalvm.polyglot.Engine$PolyglotInvalid.createHostAccess(Engine.java:991)\n    at org.graalvm.polyglot.Engine$Builder.build(Engine.java:626)\n    at org.graalvm.polyglot.Context$Builder.build(Context.java:1827)\n    at es.urjc.etsii.grafo.autoconfig.irace.runners.GraalRLangRunner.lambda$execute$0(GraalRLangRunner.java:45)\n    at java.base/java.lang.Thread.run(Thread.java:833)\n</code></pre> Cause: Multilang support is required due to config parameters, but the current JVM is not GraalVM.  Context: Multilang support is required to execute Irace if R is not installed locally and <code>irace.shell</code> is false. </p> <p>There are two options to fix the previous problem: - A: Install R locally and set <code>irace.shell=true</code> - B: Install GraalVM and launch the application using GraalVM, instead of the standard JVM.</p>"},{"location":"quickstart/troubleshooting/#the-algorithm-x-does-not-have-public-constructors","title":"The algorithm X does not have public constructors","text":"<p>Algorithms that do not have public constructors use the builder pattern. Use the static method, example: <code>SimulatedAnnealing.builder()</code>.</p>"},{"location":"quickstart/troubleshooting/#runtimeexception-could-not-found-solution-constructor-solutioninstance","title":"RuntimeException: Could not found Solution constructor Solution(Instance)","text":"<p>By default, the framework finds the solution class implementation, the instance implementation, and automatically initializes solutions under demand using the following solution class constructor: <pre><code>public class MySolution extends Solution&lt;MySolution, MyInstance&gt;{\n    // fields, etc\n\n    public MySolution(MyInstance instance){\n        // Initialize fields, etc\n    }\n\n    // other methods\n}\n</code></pre> However, there are certain cases where this strategy will fail: - If there are multiple classes extending the base Instance. - If there are multiple classes extending the base Solution. - If there is no constructor with the structure of the previous code snippet, for example because more parameters are required.</p> <p>All the previous cases are easily fixed by explaining to the framework how to initialize solutions for an instance. The only required step is extending the class SolutionBuilder, which determines how solutions are initialized.  Example: <pre><code>public class MyProblemSolutionBuilder extends SolutionBuilder&lt;VRPODSolution, VRPODInstance&gt; {\n    @Override\n    public MySolution initializeSolution(MyInstance instance) {\n        return new MySolution(instance, param1, param2, etc);\n    }\n}\n</code></pre></p> <p>If a custom SolutionBuilder implementation is provided by the user, the default strategy is automatically disabled.</p>"},{"location":"tools/complexity/","title":"Complexity Analysis","text":""},{"location":"tools/complexity/#summary","title":"Summary","text":"<p>The complexity analysis tool is designed to estimate the time complexity of each algorithm component by collecting data on method execution times. It provides insights into how each component scales according to the instance properties allowing developers to identify bottlenecks and optimize performance.</p> <p>The main difference against a traditional profiler is that profilers measure the time spent in each method. We further take this data and analyze it to understand how the execution time of each method changes with respect to the instance properties.</p> <pre><code>flowchart TD\n    A[Instances] --&gt;|Instance Properties| C[Time Data]\n    B[Algorithm components] --&gt;|Time Data| C[Offline analysis]\n    C --&gt; E[TreeMap visualization]</code></pre>"},{"location":"tools/complexity/#data-inputs","title":"Data inputs","text":""},{"location":"tools/complexity/#instance-properties","title":"Instance properties","text":""},{"location":"tools/complexity/#time-data","title":"Time data","text":"<p>Each time an observed method is executed, the following data is collected: <pre><code>{\n    \"enter\" : true,\n    \"when\" : 90191241430166,\n    \"clazz\" : \"SimpleAlgorithm\",\n    \"method\" : \"algorithm\"\n  }\n</code></pre></p> <p>and when the method finalizes: <pre><code>{\n    \"enter\" : false,\n    \"when\" : 90191243185083,\n    \"clazz\" : \"SimpleAlgorithm\",\n    \"method\" : \"algorithm\"\n  }\n</code></pre></p> <p>This way, we can calculate the time spent in each method by subtracting the timestamps of the <code>enter</code> and <code>exit</code> events. Data can be stacked, for example if the algorithm calls a constructor method, the data will look like this: <pre><code>[\n  {\n    \"enter\": true,\n    \"when\": 90191241430166,\n    \"clazz\": \"SimpleAlgorithm\",\n    \"method\": \"algorithm\"\n  },\n  {\n    \"enter\": true,\n    \"when\": 90191241446083,\n    \"clazz\": \"SleepyConstructive\",\n    \"method\": \"construct\"\n  },\n  {\n    \"enter\": false,\n    \"when\": 90191243185083,\n    \"clazz\": \"SleepyConstructive\",\n    \"method\": \"construct\"\n  },\n  {\n    \"enter\": false,\n    \"when\": 90191243186083,\n    \"clazz\": \"SimpleAlgorithm\",\n    \"method\": \"algorithm\"\n  }\n]\n</code></pre></p>"},{"location":"tools/complexity/#offline-analysis","title":"Offline analysis","text":"<p>Data is imported directly from the JSON files generated by exporting the solutions. By offline analysis, we mean that the analysis is performed after the algorithm has been executed, not during its execution, and therefore can be done with different configurations and parameters without requiring the algorithm to be run again.</p> <p>For each algorithm component that has been used, we try to fit complexity functions against each instance property individually. Fitting is performed using <code>curve_fit</code> from scipy, and the quality of the fit is measured using the configured metric (MSE by default). The best fit for each algorithm component is stored and then used to generate a treemap visualization.</p> <p>If the experiment has been run multiple times, all data is loaded and execution times are averaged for each algorithm component.</p>"},{"location":"tools/complexity/#output","title":"Output","text":""},{"location":"tools/complexity/#treemap-visualization","title":"TreeMap visualization","text":""},{"location":"tools/complexity/#fitness-chart","title":"Fitness chart","text":""}]}